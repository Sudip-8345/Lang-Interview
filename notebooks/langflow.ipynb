{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff3c920f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "587bd579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! üëã I'm Solar Open‚ÄØ100B, a large language model developed by Upstage. My knowledge is up‚Äëto‚Äëdate as of mid‚Äë2025, and I can help with answering questions, generating text, coding, translating, and more. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from os import getenv\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = \"upstage/solar-pro-3:free\",\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "response = llm.invoke('Hello')\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7490cf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 1536\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "  \"https://openrouter.ai/api/v1/embeddings\",\n",
    "  headers={\n",
    "    \"Authorization\": f\"Bearer {getenv('OPENROUTER_API_KEY')}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "  },\n",
    "  json={\n",
    "    \"model\": \"openai/text-embedding-3-small\",\n",
    "    \"input\": \"Hello world\"\n",
    "  }\n",
    ")\n",
    "\n",
    "data = response.json()\n",
    "embedding = data[\"data\"][0][\"embedding\"]\n",
    "print(f\"Embedding dimension: {len(embedding)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21ce9f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any, TypedDict, Optional, Literal, Annotated, Sequence\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import display, Markdown, Image\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, AnyMessage, BaseMessage, ToolMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3d3ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    mode : str\n",
    "    num_of_q : int\n",
    "    num_of_follow_up : int\n",
    "    position : str\n",
    "    evaluation_result: Annotated[str, add] = ''\n",
    "    hr_report: Annotated[str, add] = ''\n",
    "    company_name: str\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c711ce26",
   "metadata": {},
   "source": [
    "## *Recruiter Agent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dee7fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a decument\n",
    "pdf_path = \"../utils/interview-llm-hoang.pdf\"\n",
    "resume_path = \"../utils/Sudip_AI_Eng.pdf\"\n",
    "\n",
    "if not os.path.exists(pdf_path):\n",
    "    raise FileNotFoundError(f\"File not found: {pdf_path}\")\n",
    "\n",
    "if not os.path.exists(resume_path):\n",
    "    raise FileNotFoundError(f\"File not found: {resume_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f1ece5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF has been loaded and has 12 pages\n",
      "Resume has been loaded and has 1 pages\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_loader = PyPDFLoader(pdf_path)\n",
    "resume_loader = PyPDFLoader(resume_path)\n",
    "\n",
    "# Checks if the PDF is there\n",
    "try:\n",
    "    pages = pdf_loader.load()\n",
    "    resume = resume_loader.load()\n",
    "    print(f\"PDF has been loaded and has {len(pages)} pages\")\n",
    "    print(f\"Resume has been loaded and has {len(resume)} pages\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PDFs: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83c604f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document split into 27 chunks\n",
      "Resume split into 4 chunks\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Split pages to chunks\n",
    "text_spliter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "page_chunks = text_spliter.split_documents(pages)\n",
    "resume_chunks = text_spliter.split_documents(resume)\n",
    "\n",
    "print(f\"Document split into {len(page_chunks)} chunks\")\n",
    "print(f\"Resume split into {len(resume_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecd79111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "pdf_vectorstore = Chroma.from_documents(\n",
    "    documents=page_chunks,\n",
    "    embedding=embedding,\n",
    "    collection_name=\"interview-llm-hoang\",\n",
    "    persist_directory=\"./chroma_db/interview-llm\"\n",
    ")\n",
    "resume_vectorstore = Chroma.from_documents(\n",
    "    documents=resume_chunks,\n",
    "    embedding=embedding,\n",
    "    collection_name=\"sudip-ai-eng-resume\",\n",
    "    persist_directory=\"./chroma_db/sudip-ai-eng\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c753f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_retriever = pdf_vectorstore.as_retriever(search_type=\"similarity\")\n",
    "resume_retriever = resume_vectorstore.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0a9c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "qa_tool = create_retriever_tool(\n",
    "    retriever=pdf_retriever,\n",
    "    name=\"interview_document_retriever\",\n",
    "    description=\"Useful for answering questions about the interview document.\"\n",
    ")\n",
    "resume_tool = create_retriever_tool(\n",
    "    retriever=resume_retriever, \n",
    "    name=\"candidate_resume_retriever\",\n",
    "    description=\"Useful for answering questions about the candidate's resume.\"\n",
    ")\n",
    "tools = [qa_tool, resume_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ceaeefa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Create a tool to do retrieval of documents.\n",
       "\n",
       "    Args:\n",
       "        retriever: The retriever to use for the retrieval\n",
       "        name: The name for the tool. This will be passed to the language model,\n",
       "            so should be unique and somewhat descriptive.\n",
       "        description: The description for the tool. This will be passed to the language\n",
       "            model, so should be descriptive.\n",
       "        document_prompt: The prompt to use for the document.\n",
       "        document_separator: The separator to use between documents.\n",
       "        response_format: The tool response format.\n",
       "\n",
       "            If `\"content\"` then the output of the tool is interpreted as the contents of\n",
       "            a `ToolMessage`. If `\"content_and_artifact\"` then the output is expected to\n",
       "            be a two-tuple corresponding to the `(content, artifact)` of a `ToolMessage`\n",
       "            (artifact being a list of documents in this case).\n",
       "\n",
       "    Returns:\n",
       "        Tool class to pass to an agent.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Image\n",
    "\n",
    "display(Markdown(create_retriever_tool.__doc__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0bac9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "interviewer_prompt = PromptTemplate(\n",
    "    input_variables=[\"mode\", \"company_name\", \"position\", \"number_of_questions\", \"number_of_follow_up\"],\n",
    "    template=\"\"\"\n",
    "You are an {mode} AI interviewer for a leading tech company called {company_name}, conducting an interview for a {position} position.\n",
    "\n",
    "Your goal is to assess the candidate's technical skills, problem-solving abilities, communication skills, and experience relevant to data science roles.\n",
    "\n",
    "Maintain a professional yet approachable tone.\n",
    "\n",
    "You have access to two tools:\n",
    "1. `interview_document_retriever`: This tool can search a knowledge base of interview questions related to the {position} position. Use this tool to find relevant questions to ask the candidate.\n",
    "2. `candidate_resume_retriever`: This tool can search the candidate's resume to find information about their past projects and experience. Use this tool to ask relevant projects from their resume like {position} projects.\n",
    "\n",
    "Interview Structure:\n",
    "- Start with a friendly introduction\n",
    "  - Ask the candidate to introduce themselves\n",
    "  - Ask about a specific project from their resume\n",
    "- Ask {number_of_questions} main questions from the knowledge base\n",
    "- Ask up to {number_of_follow_up} follow-up questions if answers are vague\n",
    "- End with \"Thank you, that's it for today.\"\n",
    "\n",
    "Guidelines:\n",
    "- Maintain a {mode} tone throughout\n",
    "- Number your questions clearly (Question 1, Question 2, etc.)\n",
    "- If asked irrelevant questions, respond with \"Sorry, this is out of scope.\"\n",
    "\n",
    "IMPORTANT RESPONSE FORMAT:\n",
    "- You MUST always provide a spoken response in the content field, even when using tools.\n",
    "- Your response should be clean spoken English only - no markdown, no special symbols, no JSON, no code blocks, no tool logs, no formatting characters.\n",
    "- Keep only natural readable sentences that can be spoken aloud.\n",
    "- When you need information from tools, first respond to acknowledge the candidate, then use the tools.\n",
    "\n",
    "Begin the interview now.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef18ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "def recruiter(state: AgentState) -> AgentState:\n",
    "    '''the recruiter agent conducts interviews using the interviewer prompt and tools to assess candidates.'''\n",
    "    sys_prompt = SystemMessage(content=interviewer_prompt.format(\n",
    "        mode=state['mode'],\n",
    "        company_name=state['company_name'],\n",
    "        position=state['position'],\n",
    "        number_of_questions=state['num_of_q'],\n",
    "        number_of_follow_up=state['num_of_follow_up']\n",
    "    ))\n",
    "    all_messages = [sys_prompt] + state['messages']\n",
    "    result = llm.bind_tools(tools).invoke(all_messages)\n",
    "    \n",
    "    # If the model made tool calls but returned empty content, execute tools and get response\n",
    "    if hasattr(result, 'tool_calls') and result.tool_calls and not result.content:\n",
    "        # Execute tool calls\n",
    "        tool_node = ToolNode(tools)\n",
    "        tool_results = tool_node.invoke({\"messages\": [result]})\n",
    "        \n",
    "        # Add tool results to messages and get final response\n",
    "        updated_messages = all_messages + [result] + tool_results['messages']\n",
    "        final_result = llm.bind_tools(tools).invoke(updated_messages)\n",
    "        return {\"messages\": [result] + tool_results['messages'] + [final_result]}\n",
    "    \n",
    "    return {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20b81fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState) -> str:\n",
    "    '''decides whether to continue the interview based on the agent's state.'''\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    \n",
    "    # Check if agent wants to use tools\n",
    "    if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
    "        return \"invoke_tools\"\n",
    "    \n",
    "    # Check if interview is finished\n",
    "    if \"Thank you, that's it for today.\" in last_msg.content:\n",
    "        return \"end\"\n",
    "    \n",
    "    # Continue conversation\n",
    "    return \"continue_convo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfb64932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Thank you for taking the time to speak with us today Sudip. Could you briefly introduce yourself and share a specific project from your resume that you'd like to discuss? This helps us understand your background and technical interests.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 273, 'prompt_tokens': 778, 'total_tokens': 1051, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': 0, 'reasoning_tokens': 223, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 64}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'upstage/solar-pro-3:free', 'system_fingerprint': None, 'id': 'gen-1769776335-CSb3jK8F5n6suetUoZIq', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c0ee3-c4a9-7b00-8bc8-d453f1b2ea2d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 778, 'output_tokens': 273, 'total_tokens': 1051, 'input_token_details': {'audio': 0, 'cache_read': 64}, 'output_token_details': {'audio': 0, 'reasoning': 223}})]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recruiter(AgentState(\n",
    "    mode=\"friendly\",\n",
    "    num_of_q=1,\n",
    "    num_of_follow_up=1,\n",
    "    position=\"AI Engineer\",\n",
    "    company_name=\"Tech Innovators Inc.\",\n",
    "    messages=[HumanMessage(content=\"Hello, I am Sudip Das, I am an AI Engineer with 1 year of experience in building AI systems.\")]\n",
    "))['messages']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230eab41",
   "metadata": {},
   "source": [
    "## *Evaluator Agent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "993f6b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from os import getenv\n",
    "\n",
    "evallm = ChatOpenAI(\n",
    "    model = \"upstage/solar-pro-3:free\",\n",
    "    api_key=getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\"\n",
    ")\n",
    "\n",
    "# response = evallm.invoke('Hello')\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61165369",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_prompt = PromptTemplate(\n",
    "    input_variables=[\"num_of_q\", \"num_of_follow_up\", \"position\"],\n",
    "    template=\"\"\"You are an AI evaluator for a job interview. Your task is to evaluate the candidate's responses based\\\\\n",
    "    on their relevance, clarity, and depth.\n",
    "    You will receive one Introduction question, one project question, and {num_of_q} technical questions with up to {num_of_follow_up} follow up questions\\\\\n",
    "    about {position} position.\n",
    "    Ignore any irrelevant questions or answers.\n",
    "    You evaluate each response with a score from 1 to 10, where 1 is the lowest and 10 is the highest.\n",
    "    The context of the interview is as follows:\n",
    "        Introduction question:\n",
    "        Project question:\n",
    "        Technical questions:\n",
    "    each question could have a follow-up question, if so you should evaluate the main question only and assume the follow up answer is appended to the main answer.\n",
    "    Usually the main technical question is in the following format:\n",
    "        Question one: Example question one?\n",
    "        Question two: Example question two?\n",
    "    you should evaluate the main question only and assume the follow up answer is appended to the main answer.\n",
    "    If you don't have enough information to evaluate a Technical question, use the tool `interview_document_retriever` to get more information about the question.\n",
    "    You should output the evaluation in the following format:\n",
    "    Evaluation:\n",
    "        1. Introduction question: [score] - [reasoning]\n",
    "        2. Project question: [score] - [reasoning]\n",
    "        3. Technical question one: [score] - [reasoning]\n",
    "        4. Technical question two: [score] - [reasoning]\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9601c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator(state: AgentState) -> AgentState:\n",
    "    '''the evaluator agent assesses candidate responses using the evaluator prompt.'''\n",
    "    sys_prompt = evaluator_prompt.format(\n",
    "        num_of_q=state['num_of_q'],\n",
    "        num_of_follow_up=state['num_of_follow_up'],\n",
    "        position=state['position']\n",
    "    )\n",
    "    sys_msg = SystemMessage(content=sys_prompt)\n",
    "    interview_base = []\n",
    "    for msg in state['messages']:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            interview_base.append('Candidate: ' + str(msg.content))\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            interview_base.append('Interviewer: ' + str(msg.content))\n",
    "    \n",
    "    all_messages = [sys_msg, HumanMessage(content='\\n'.join(interview_base))]\n",
    "    evallm_with_tools = evallm.bind_tools([qa_tool])\n",
    "    results = evallm_with_tools.invoke(all_messages)\n",
    "    return {'messages': [AIMessage(content=results.content)], \n",
    "            'evaluation_result': results.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9042ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tools_condition(state: AgentState):\n",
    "    last_message = state['messages'][-1] if state['messages'] else None\n",
    "    if last_message is None:\n",
    "        return 'WAIT_FOR_HUMAN'\n",
    "    if isinstance(last_message, AIMessage) and hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    elif isinstance(last_message, AIMessage) and 'that\\'s it for today' in last_message.content.lower():\n",
    "        return \"END_CONVERSATION\"\n",
    "    else:\n",
    "        return 'WAIT_FOR_HUMAN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e5b148",
   "metadata": {},
   "source": [
    "## *Report Writer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94f42f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER, TA_LEFT\n",
    "from langchain_core.tools import tool\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "808c460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, HRFlowable\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY\n",
    "from reportlab.lib.colors import HexColor, black, white\n",
    "from reportlab.lib.units import inch\n",
    "from datetime import datetime\n",
    "\n",
    "# Define professional color scheme\n",
    "PRIMARY_COLOR = HexColor(\"#1a365d\")      # Dark blue\n",
    "SECONDARY_COLOR = HexColor(\"#2b6cb0\")    # Medium blue  \n",
    "ACCENT_COLOR = HexColor(\"#38a169\")       # Green for positive\n",
    "WARNING_COLOR = HexColor(\"#dd6b20\")      # Orange for areas to improve\n",
    "LIGHT_BG = HexColor(\"#f7fafc\")           # Light gray background\n",
    "BORDER_COLOR = HexColor(\"#e2e8f0\")       # Border color\n",
    "\n",
    "@tool\n",
    "def save_report_as_pdf(report_content: str, filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Saves the provided report content as a professionally styled PDF file.\n",
    "\n",
    "    Args:\n",
    "        report_content (str): The full text content of the HR report.\n",
    "        filename (str): The desired name for the PDF file (e.g., \"HR_Interview_Report_CandidateX.pdf\").\n",
    "                        Do NOT include path, just the filename. The file will be saved in the current directory.\n",
    "\n",
    "    Returns:\n",
    "        str: The full path to the saved PDF file if successful, otherwise an error message.\n",
    "    \"\"\"\n",
    "    if not filename.endswith(\".pdf\"):\n",
    "        filename += \".pdf\"\n",
    "    \n",
    "    safe_filename = os.path.basename(filename)\n",
    "\n",
    "    try:\n",
    "        doc = SimpleDocTemplate(\n",
    "            safe_filename, \n",
    "            pagesize=letter,\n",
    "            rightMargin=0.75*inch,\n",
    "            leftMargin=0.75*inch,\n",
    "            topMargin=0.75*inch,\n",
    "            bottomMargin=0.75*inch\n",
    "        )\n",
    "        styles = getSampleStyleSheet()\n",
    "        \n",
    "        # Custom styles for a catchy report\n",
    "        title_style = ParagraphStyle(\n",
    "            'CustomTitle',\n",
    "            parent=styles['Title'],\n",
    "            fontSize=28,\n",
    "            textColor=PRIMARY_COLOR,\n",
    "            alignment=TA_CENTER,\n",
    "            spaceAfter=6,\n",
    "            fontName='Helvetica-Bold'\n",
    "        )\n",
    "        \n",
    "        subtitle_style = ParagraphStyle(\n",
    "            'CustomSubtitle',\n",
    "            parent=styles['Normal'],\n",
    "            fontSize=12,\n",
    "            textColor=SECONDARY_COLOR,\n",
    "            alignment=TA_CENTER,\n",
    "            spaceAfter=20,\n",
    "            fontName='Helvetica-Oblique'\n",
    "        )\n",
    "        \n",
    "        section_header_style = ParagraphStyle(\n",
    "            'SectionHeader',\n",
    "            parent=styles['Heading2'],\n",
    "            fontSize=14,\n",
    "            textColor=white,\n",
    "            backColor=PRIMARY_COLOR,\n",
    "            borderPadding=(8, 8, 8, 8),\n",
    "            spaceBefore=16,\n",
    "            spaceAfter=10,\n",
    "            fontName='Helvetica-Bold',\n",
    "            leftIndent=0,\n",
    "            rightIndent=0\n",
    "        )\n",
    "        \n",
    "        body_style = ParagraphStyle(\n",
    "            'CustomBody',\n",
    "            parent=styles['Normal'],\n",
    "            fontSize=11,\n",
    "            textColor=black,\n",
    "            alignment=TA_JUSTIFY,\n",
    "            spaceAfter=8,\n",
    "            leading=16,\n",
    "            fontName='Helvetica'\n",
    "        )\n",
    "        \n",
    "        highlight_style = ParagraphStyle(\n",
    "            'Highlight',\n",
    "            parent=styles['Normal'],\n",
    "            fontSize=11,\n",
    "            textColor=ACCENT_COLOR,\n",
    "            spaceAfter=6,\n",
    "            fontName='Helvetica-Bold',\n",
    "            leftIndent=15,\n",
    "            bulletIndent=0\n",
    "        )\n",
    "        \n",
    "        warning_style = ParagraphStyle(\n",
    "            'Warning',\n",
    "            parent=styles['Normal'],\n",
    "            fontSize=11,\n",
    "            textColor=WARNING_COLOR,\n",
    "            spaceAfter=6,\n",
    "            fontName='Helvetica-Bold',\n",
    "            leftIndent=15\n",
    "        )\n",
    "\n",
    "        story = []\n",
    "        \n",
    "        # Header section with styled title\n",
    "        story.append(Paragraph(\"üìã HR Interview Report\", title_style))\n",
    "        story.append(Paragraph(f\"Generated on {datetime.now().strftime('%B %d, %Y at %I:%M %p')}\", subtitle_style))\n",
    "        \n",
    "        # Decorative line\n",
    "        story.append(HRFlowable(\n",
    "            width=\"100%\",\n",
    "            thickness=2,\n",
    "            color=PRIMARY_COLOR,\n",
    "            spaceBefore=5,\n",
    "            spaceAfter=20\n",
    "        ))\n",
    "\n",
    "        # Section mappings for styling\n",
    "        section_keywords = {\n",
    "            'overall suitability': ('üìä Overall Suitability', section_header_style),\n",
    "            'strengths': ('‚úÖ Strengths', section_header_style),\n",
    "            'areas for development': ('‚ö†Ô∏è Areas for Development', section_header_style),\n",
    "            'weaknesses': ('‚ö†Ô∏è Areas for Development', section_header_style),\n",
    "            'technical skills': ('üíª Key Technical Skills', section_header_style),\n",
    "            'problem-solving': ('üß© Problem-Solving Approach', section_header_style),\n",
    "            'communication': ('üí¨ Communication Skills', section_header_style),\n",
    "            'experience': ('üìÅ Relevant Experience', section_header_style),\n",
    "            'recommendations': ('üéØ Recommendations', section_header_style),\n",
    "            'candidate summary': ('üë§ Candidate Summary', section_header_style),\n",
    "        }\n",
    "\n",
    "        # Process report content\n",
    "        paragraphs = report_content.split('\\n')\n",
    "        \n",
    "        for para_text in paragraphs:\n",
    "            para_stripped = para_text.strip()\n",
    "            if not para_stripped:\n",
    "                continue\n",
    "                \n",
    "            # Check if it's a section header\n",
    "            is_section = False\n",
    "            for keyword, (emoji_title, style) in section_keywords.items():\n",
    "                if keyword in para_stripped.lower() and (para_stripped.endswith(':') or len(para_stripped) < 60):\n",
    "                    story.append(Spacer(1, 10))\n",
    "                    story.append(Paragraph(emoji_title, style))\n",
    "                    is_section = True\n",
    "                    break\n",
    "            \n",
    "            if not is_section:\n",
    "                # Check for bullet points or list items\n",
    "                if para_stripped.startswith(('-', '‚Ä¢', '*', '‚Äì')):\n",
    "                    clean_text = para_stripped.lstrip('-‚Ä¢*‚Äì ').strip()\n",
    "                    # Color code based on content type\n",
    "                    if any(word in para_stripped.lower() for word in ['strength', 'excellent', 'strong', 'proficient', 'demonstrated']):\n",
    "                        story.append(Paragraph(f\"‚úì {clean_text}\", highlight_style))\n",
    "                    elif any(word in para_stripped.lower() for word in ['improve', 'develop', 'weakness', 'gap', 'lacking']):\n",
    "                        story.append(Paragraph(f\"‚ñ≥ {clean_text}\", warning_style))\n",
    "                    else:\n",
    "                        story.append(Paragraph(f\"‚Ä¢ {clean_text}\", body_style))\n",
    "                else:\n",
    "                    story.append(Paragraph(para_stripped, body_style))\n",
    "\n",
    "        # Footer decorative line\n",
    "        story.append(Spacer(1, 30))\n",
    "        story.append(HRFlowable(\n",
    "            width=\"100%\",\n",
    "            thickness=1,\n",
    "            color=BORDER_COLOR,\n",
    "            spaceBefore=10,\n",
    "            spaceAfter=10\n",
    "        ))\n",
    "        \n",
    "        # Footer text\n",
    "        footer_style = ParagraphStyle(\n",
    "            'Footer',\n",
    "            parent=styles['Normal'],\n",
    "            fontSize=9,\n",
    "            textColor=HexColor(\"#718096\"),\n",
    "            alignment=TA_CENTER\n",
    "        )\n",
    "        story.append(Paragraph(\"This report was automatically generated by AI Interview Assistant\", footer_style))\n",
    "        story.append(Paragraph(\"Confidential - For HR Use Only\", footer_style))\n",
    "\n",
    "        doc.build(story)\n",
    "        return f\"‚úÖ Report successfully saved to: {os.path.abspath(safe_filename)}\"\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return f\"‚ùå Error saving report as PDF: {e}\"\n",
    "\n",
    "# Make sure this tool is available to your report_writer_llm\n",
    "report_writer_tools = [save_report_as_pdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "475c2e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_writer_prompt = PromptTemplate(\n",
    "    input_variables=[\"position\", \"company_name\", \"interview_transcript\", \"evaluation_report\"],\n",
    "    template=\"\"\"You are an AI HR Report Writer. Your task is to synthesize information from a job interview transcript and its evaluation into a concise, professional report for Human Resources at {company_name}.\n",
    "\n",
    "The interview was for a **{position}** position.\n",
    "\n",
    "Your report should focus on key takeaways relevant to HR's decision-making, including but not limited to:\n",
    "-   **Candidate's Overall Suitability:** A brief summary of whether the candidate seems suitable for the role based on their performance.\n",
    "-   **Strengths:** Specific areas where the candidate performed well, supported by examples from the transcript if clear.\n",
    "-   **Areas for Development/Weaknesses:** Specific areas where the candidate struggled or showed gaps, supported by examples from the transcript if clear.\n",
    "-   **Key Technical Skills Demonstrated:** List any core technical skills (e.g., Python, SQL, ML algorithms, data analysis, specific frameworks) explicitly mentioned or clearly demonstrated by the candidate's answers.\n",
    "-   **Problem-Solving Approach:** Insights into how the candidate approaches technical problems or challenges (if discernible).\n",
    "-   **Communication Skills:** Assessment of clarity, conciseness, and overall effectiveness of their communication during the interview.\n",
    "-   **Relevant Experience Highlights:** Any particularly relevant past projects or experiences highlighted by the candidate.\n",
    "-   **Recommendations (Optional):** A high-level recommendation (e.g., \"Proceed to next round,\" \"Consider for a different role,\" \"Not a good fit at this time\").\n",
    "\n",
    "You will be provided with:\n",
    "1.  **Full Interview Transcript:** The complete conversation between the recruiter and the candidate.\n",
    "2.  **Evaluation Report:** A structured evaluation of the candidate's responses provided by an AI evaluator, including scores and reasoning for each question.\n",
    "\n",
    "**Instructions for Report Generation:**\n",
    "-   **Conciseness:** Be brief and to the point. HR personnel have limited time.\n",
    "-   **Professional Tone:** Maintain a neutral, objective, and professional tone throughout the report.\n",
    "-   **Evidence-Based:** Support your points with specific references or inferences from the provided transcript and evaluation. Do NOT invent information.\n",
    "-   **Structure:** Organize your report with clear headings for each section (e.g., \"Candidate Summary,\" \"Strengths,\" \"Areas for Development,\" etc.).\n",
    "-   **Format:** Present the report as a single, well-formatted text block. Do not include any conversational filler.\n",
    "-   **Tool Usage:** After generating the report, you MUST use the `save_report_as_pdf` tool to save the report to a file. Choose a descriptive filename like \"Interview_Report_{company_name}_{position}.pdf\".\n",
    "    * Example Tool Call: `tool_code: print(save_report_as_pdf(report_content=\"[Your generated report text]\", filename=\"Interview_Report_JaneDoe_DataScientist.pdf\"))`\n",
    "\n",
    "---\n",
    "**Interview Transcript:**\n",
    "{interview_transcript}\n",
    "\n",
    "---\n",
    "**Evaluation Report:**\n",
    "{evaluation_report}\n",
    "\n",
    "Dont forget to save the report in a pdf using `save_report_as_pdf` tool.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "538e9309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_writer(state: AgentState) -> AgentState:\n",
    "    \"\"\" Generates a report based on the interview transcript and evaluation \"\"\"\n",
    "    interviewer_transcript = []\n",
    "    for m in state[\"messages\"]:\n",
    "        if isinstance(m, HumanMessage):\n",
    "            interviewer_transcript.append('Candidate: ' + str(m.content))\n",
    "        elif isinstance(m, AIMessage):\n",
    "            if 'Evaluation:\\n1. Introduction question' not in m.content:\n",
    "                interviewer_transcript.append('AI Recruiter: ' + str(m.content))\n",
    "    \n",
    "    evaluation_report = [m.content for m in state[\"messages\"] if isinstance(m, AIMessage) and 'Evaluation:\\n1. Introduction question' in m.content]\n",
    "    sys_prompt = report_writer_prompt.format(\n",
    "        position=state['position'],\n",
    "        company_name=state['company_name'],\n",
    "        interview_transcript= '\\n'.join(interviewer_transcript),\n",
    "        evaluation_report=evaluation_report\n",
    "    )\n",
    "    sys_message = SystemMessage(content=sys_prompt)\n",
    "    all_messages = [sys_message, HumanMessage(content='Generate the report now.')]\n",
    "    result = llm.bind_tools(report_writer_tools).invoke(all_messages)\n",
    "    return {\"messages\": [result], \"hr_report\": result.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dde980af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Generates a report based on the interview transcript and evaluation "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(report_writer.__doc__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb01581",
   "metadata": {},
   "source": [
    "## *LangGraph Workflow*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eaa05e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1cbb19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1e114cde1e0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------- Nodes ---------------\n",
    "# Define the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add the agent node\n",
    "workflow.add_node(\"recruiter\", recruiter)\n",
    "\n",
    "# Add tool node\n",
    "tool_node = ToolNode(tools)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Add the evaluator node\n",
    "workflow.add_node(\"evaluator\", evaluator)\n",
    "\n",
    "# Add evaluator tool node (using qa_tool for interview document retrieval)\n",
    "evaluator_tool_node = ToolNode([qa_tool])\n",
    "workflow.add_node(\"evaluator_tools\", evaluator_tool_node)\n",
    "\n",
    "# Add report writer node\n",
    "workflow.add_node(\"report_writer\", report_writer)\n",
    "\n",
    "# Add the save report tool node\n",
    "report_writer_tool_node = ToolNode([save_report_as_pdf])\n",
    "workflow.add_node(\"report_writer_tools\", report_writer_tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5dfc5103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001E1198372C0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------- Work flow -------------------\n",
    "# Set the entry point\n",
    "workflow.set_entry_point(\"recruiter\")\n",
    "\n",
    "# For now, let's assume the agent will either call a tool or finish\n",
    "workflow.add_conditional_edges(\n",
    "    \"recruiter\",\n",
    "    custom_tools_condition,\n",
    "    {\n",
    "        \"tools\": \"tools\",  # If tools are called, go to the tools node\n",
    "        \"END_CONVERSATION\": \"evaluator\",  # If conversation ends, go to evaluator\n",
    "        \"WAIT_FOR_HUMAN\": END  # If waiting for human, go to end\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edge from tools back to the recruiter\n",
    "workflow.add_edge(\"tools\", \"recruiter\")\n",
    "\n",
    "# Add edge from evaluator tools to evaluator\n",
    "workflow.add_edge(\"evaluator_tools\", \"evaluator\")\n",
    "\n",
    "# Define edges for evaluator node\n",
    "workflow.add_conditional_edges(\n",
    "    \"evaluator\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"evaluator_tools\",  \n",
    "        END: \"report_writer\"\n",
    "    }\n",
    ")\n",
    "# Add edge from evaluator to report writer\n",
    "workflow.add_edge(\"evaluator\", \"report_writer\")\n",
    "\n",
    "# Define edges for report writer node\n",
    "workflow.add_conditional_edges(\n",
    "    \"report_writer\",\n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"report_writer_tools\",  \n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9591ae5",
   "metadata": {},
   "source": [
    "**Chat Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "487116b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop(initial_state: AgentState):\n",
    "    curr_state = initial_state.copy()\n",
    "    print(\"\"\"Starting chat loop... \n",
    "          Type 'exit' or 'quit' to end.\"\"\")\n",
    "    \n",
    "    first_out = app.invoke(curr_state)\n",
    "    # Don't use update - directly replace the state with the output\n",
    "    curr_state = first_out\n",
    "    ai_message = first_out['messages'][-1]\n",
    "    if isinstance(ai_message, AIMessage):\n",
    "        print(f'Recruiter:\\n')\n",
    "        ai_message.pretty_print()\n",
    "        if 'that\\'s it for today' in ai_message.content.lower():\n",
    "            print(\"Conversation ended by Recruiter.\")\n",
    "            return curr_state\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print(\"Exiting chat.\")\n",
    "            break\n",
    "        \n",
    "        # Create a new input state with the human message added\n",
    "        input_state = {\n",
    "            **curr_state,\n",
    "            'messages': curr_state['messages'] + [HumanMessage(content=user_input)]\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            result = app.invoke(input_state)\n",
    "            # Replace state entirely instead of updating\n",
    "            curr_state = result\n",
    "        except Exception as e:\n",
    "            print(f\"Error during invocation: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "            \n",
    "        ai_message = result['messages'][-1]\n",
    "        if isinstance(ai_message, AIMessage):\n",
    "            print(f'Recruiter:\\n')\n",
    "            ai_message.pretty_print()\n",
    "            if 'that\\'s it for today' in ai_message.content.lower():\n",
    "                print(\"Conversation ended by Recruiter.\")\n",
    "                break\n",
    "        elif isinstance(ai_message, ToolMessage):\n",
    "            print(f'Recruiter used tool: {ai_message.name}')\n",
    "            ai_message.pretty_print()\n",
    "        else:\n",
    "            print(f\"AI Recruiter (Other Message Type): \\n\")\n",
    "            ai_message.pretty_print()\n",
    "        \n",
    "    return curr_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4921832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chat loop... \n",
      "          Type 'exit' or 'quit' to end.\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! I'm your interviewer today from Data Solutions Inc. We're excited to have you here. To start, could you please introduce yourself briefly?\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "tool used: `candidate_resume_retriever`\n",
      "\n",
      "Thank you for the introduction! I noticed your project \"Multimodal-RAG-Forge\" on your resume. Could you tell me more about the challenges you faced while building this multimodal RAG and OCR-based summarization system and how you overcame them?\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "tool used: `interview_document_retriever`\n",
      "\n",
      "Question one: What challenges do LLMs face in deployment?\n",
      "\n",
      "Question two: How does the attention mechanism function in transformer models?\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for the detailed response. Let's move on to the next question.\n",
      "\n",
      "Question one: How does the attention mechanism function in transformer models?\n",
      "\n",
      "Question two: Can you explain how you would optimize the attention mechanism for efficiency in a real-world application?\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for the detailed explanation. Let's move on to the next question.\n",
      "\n",
      "Question one: What is Chain-of-Thought (CoT) prompting, and how does it aid reasoning?\n",
      "\n",
      "Question two: Can you provide an example of how you might apply CoT prompting in a real-world scenario?\n",
      "Recruiter used tool: save_report_as_pdf\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_report_as_pdf\n",
      "\n",
      "Report successfully saved to: c:\\Users\\Sudip Das\\SudipWorkspace\\Projects\\LangInterview\\notebooks\\Interview_Report_Data Solutions Inc._AI Engineer.pdf\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Certainly! Here‚Äôs a structured feedback based on your performance in the interview:\n",
      "\n",
      "---\n",
      "\n",
      "### **Strengths:**\n",
      "1. **Technical Depth:**\n",
      "   - You demonstrated a strong understanding of AI concepts, particularly in multimodal systems, RAG pipelines, and MLOps. Your explanation of the \"Multimodal-RAG-Forge\" project was detailed and showcased your ability to tackle complex challenges like latency and API reliability.\n",
      "   - Your knowledge of Chain-of-Thought (CoT) prompting and attention mechanisms was evident, and you tied these concepts to real-world applications effectively.\n",
      "\n",
      "2. **Problem-Solving Skills:**\n",
      "   - You provided clear examples of how you addressed challenges in your projects, such as implementing custom caching to reduce preprocessing steps and using safe fallbacks to handle OCR/LLM failures. This highlights your ability to think critically and optimize systems.\n",
      "\n",
      "3. **Relevant Experience:**\n",
      "   - Your internship at Unihox and your academic background in Mathematics and Computing align well with the AI Engineer role. Your work on high-concurrency backends and AI-driven SaaS tools demonstrates practical experience that is valuable for this position.\n",
      "\n",
      "4. **Communication:**\n",
      "   - You articulated your thoughts clearly and concisely, making complex technical concepts understandable. This is a crucial skill for collaborating with teams and stakeholders.\n",
      "\n",
      "---\n",
      "\n",
      "### **Areas for Improvement:**\n",
      "1. **Structured Responses:**\n",
      "   - While your explanations were detailed, some responses could have been more structured. For example, when discussing the attention mechanism in transformers, breaking down the explanation into smaller, logical steps would have made it easier to follow.\n",
      "\n",
      "2. **Real-World Examples:**\n",
      "   - For questions like applying CoT prompting in a real-world scenario, providing a concrete example would have strengthened your response. This helps interviewers visualize how you would implement solutions in practice.\n",
      "\n",
      "3. **Conciseness:**\n",
      "   - At times, your responses were slightly verbose. Practicing concise answers while retaining key details can make your communication even more effective, especially in time-sensitive interview settings.\n",
      "\n",
      "---\n",
      "\n",
      "### **Specific Feedback on Responses:**\n",
      "1. **Multimodal-RAG-Forge Project:**\n",
      "   - **Strength:** You did an excellent job explaining the challenges and solutions, such as modular pipelines and caching. This showcased your hands-on experience and problem-solving skills.\n",
      "   - **Improvement:** You could have briefly mentioned the impact of these solutions (e.g., performance metrics or user feedback) to quantify your success.\n",
      "\n",
      "2. **LLM Deployment Challenges:**\n",
      "   - **Strength:** You covered key challenges like computational costs, latency, and reliability, and tied them to your experience with local fallbacks and MLOps tools.\n",
      "   - **Improvement:** You could have expanded on how you specifically addressed these challenges in your projects, such as tools or methodologies used.\n",
      "\n",
      "3. **Attention Mechanism:**\n",
      "   - **Strength:** You discussed semantic ambiguity and the limitations of attention mechanisms, showing a deep understanding of the topic.\n",
      "   - **Improvement:** A clearer explanation of how the attention mechanism functions (e.g., query, key, value vectors) would have made your response more comprehensive.\n",
      "\n",
      "4. **Chain-of-Thought Prompting:**\n",
      "   - **Strength:** You provided a clear definition of CoT prompting and its benefits.\n",
      "   - **Improvement:** Adding an example of how you applied CoT prompting in a project or hypothetical scenario would have made your response more impactful.\n",
      "\n",
      "---\n",
      "\n",
      "### **Overall Impression:**\n",
      "You are a strong candidate for the AI Engineer role, with a solid foundation in AI/ML concepts, practical experience, and effective communication skills. With minor improvements in structuring your responses and providing real-world examples, you can further enhance your interview performance.\n",
      "\n",
      "---\n",
      "\n",
      "### **Recommendations for Future Interviews:**\n",
      "1. **Practice Structured Responses:** Use frameworks like STAR (Situation, Task, Action, Result) to organize your answers, especially for behavioral or project-related questions.\n",
      "2. **Prepare Examples:** Think of specific examples where you applied technical concepts (e.g., CoT prompting) in your projects or internships.\n",
      "3. **Mock Interviews:** Conduct mock interviews to refine your conciseness and clarity. Focus on delivering key points succinctly while retaining depth.\n",
      "\n",
      "---\n",
      "\n",
      "Keep up the great work, and best of luck in your future interviews! Let me know if you'd like to discuss any of this feedback further.\n",
      "Recruiter used tool: save_report_as_pdf\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_report_as_pdf\n",
      "\n",
      "Report successfully saved to: c:\\Users\\Sudip Das\\SudipWorkspace\\Projects\\LangInterview\\notebooks\\Interview_Report_Data Solutions Inc._AI Engineer.pdf\n",
      "Exiting chat.\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"mode\": \"friendly\",\n",
    "    \"num_of_q\": 1,\n",
    "    \"num_of_follow_up\": 1,\n",
    "    \"position\": \"AI Engineer\",\n",
    "    \"company_name\": \"Data Solutions Inc.\",\n",
    "    \"messages\": [HumanMessage(content=\"Hi\")],\n",
    "    \"evaluation_result\": \"\",\n",
    "    \"hr_report\": \"\"\n",
    "}\n",
    "# Start the chat loop\n",
    "final_state = chat_loop(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "823d6841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mode': 'friendly',\n",
       " 'num_of_q': 1,\n",
       " 'num_of_follow_up': 1,\n",
       " 'position': 'AI Engineer',\n",
       " 'evaluation_result': 'Evaluation:\\n1. **Introduction question: 9/10** - The candidate provided a clear and concise introduction, highlighting their academic background, relevant skills (Linear Algebra, Optimization), and practical experience (internship at Unihox). They also mentioned their passion for AI and a specific project, demonstrating alignment with the role.\\n\\n2. **Project question: 9/10** - The candidate explained the challenges faced in the \"Multimodal-RAG-Forge\" project in detail, including technical solutions like modular pipelines, custom caching, and handling latency. Their response demonstrated problem-solving skills and a deep understanding of the project.\\n\\n3. **Technical question one (Challenges in LLM deployment): 8/10** - The candidate addressed key challenges such as computational costs, latency, reliability, and data security. They also tied their response to real-world solutions like local fallbacks and MLOps tools, showing practical knowledge.\\n\\n4. **Technical question two (Attention mechanism in transformers): 7/10** - The candidate discussed semantic ambiguity and the limitations of the attention mechanism, such as handling ambiguous references and long sequences. However, the response could have been more structured and included a clearer explanation of how the attention mechanism functions.\\n\\n5. **Technical question one (Chain-of-Thought prompting): 8/10** - The candidate provided a clear definition of CoT prompting and explained its benefits in improving reasoning and reducing hallucinations. The response was relevant and demonstrated understanding.\\n\\n6. **Technical question two (Application of CoT prompting): N/A** - The candidate did not provide an example of applying CoT prompting in a real-world scenario, so this part could not be evaluated.Evaluation:\\n1. **Introduction question: 9/10** - The candidate provided a clear and concise introduction, highlighting their academic background, relevant skills (Linear Algebra, Optimization), and practical experience (internship at Unihox). They also mentioned their passion for AI and a specific project, demonstrating alignment with the role.\\n\\n2. **Project question: 9/10** - The candidate explained the challenges faced in the \"Multimodal-RAG-Forge\" project in detail, including technical solutions like modular pipelines, custom caching, and handling latency. Their response demonstrated problem-solving skills and a deep understanding of the project.\\n\\n3. **Technical question one (Challenges in LLM deployment): 8/10** - The candidate addressed key challenges such as computational costs, latency, reliability, and data security. They also tied their response to real-world solutions like local fallbacks and MLOps tools, showing practical knowledge.\\n\\n4. **Technical question two (Attention mechanism in transformers): 7/10** - The candidate discussed semantic ambiguity and the limitations of the attention mechanism, such as handling ambiguous references and long sequences. However, the response could have been more structured and included a clearer explanation of how the attention mechanism functions.\\n\\n5. **Technical question one (Chain-of-Thought prompting): 8/10** - The candidate provided a clear definition of CoT prompting and explained its benefits in improving reasoning and reducing hallucinations. The response was relevant and demonstrated understanding.\\n\\n6. **Technical question two (Application of CoT prompting): N/A** - The candidate did not provide an example of applying CoT prompting in a real-world scenario, so this part could not be evaluated.',\n",
       " 'hr_report': '### HR Interview Report: AI Engineer Position\\n**Candidate Summary:**\\nThe candidate is a strong fit for the AI Engineer role at Data Solutions Inc. They demonstrated a solid academic foundation in Mathematics and Computing, complemented by practical experience in AI engineering, particularly in multimodal systems and MLOps. Their responses were technically sound, and they showcased problem-solving skills and a deep understanding of AI challenges.\\n\\n---\\n\\n### Strengths:\\n1. **Technical Expertise:** The candidate exhibited strong knowledge of AI systems, including multimodal pipelines, attention mechanisms, and Chain-of-Thought (CoT) prompting. Their explanation of the \"Multimodal-RAG-Forge\" project highlighted their ability to integrate fragmented data formats and optimize system performance.\\n2. **Problem-Solving Skills:** They effectively addressed challenges such as latency, API reliability, and semantic ambiguity, providing clear examples of solutions implemented in their projects.\\n3. **Relevant Experience:** Their internship at Unihox and academic background align well with the role, particularly their work on high-concurrency backends and AI-driven SaaS tools.\\n4. **Communication Skills:** The candidate communicated their ideas clearly and concisely, demonstrating the ability to explain complex technical concepts in an understandable manner.\\n\\n---\\n\\n### Areas for Development/Weaknesses:\\n1. **Structured Explanations:** While the candidate provided detailed responses, some explanations, such as the attention mechanism in transformers, could have been more structured and concise.\\n2. **Real-World Application Examples:** The candidate did not provide a specific example of applying CoT prompting in a real-world scenario, which would have strengthened their response.\\n\\n---\\n\\n### Key Technical Skills Demonstrated:\\n- **Programming Languages:** Python (implied from project descriptions).\\n- **AI/ML Frameworks:** LlamaIndex, Gemini, Whisper, MoviePy, Unstructured.\\n- **MLOps Tools:** MLflow, Docker.\\n- **Concepts:** Multimodal RAG, attention mechanisms, Chain-of-Thought prompting, high-concurrency backends.\\n\\n---\\n\\n### Problem-Solving Approach:\\nThe candidate approaches technical challenges methodically, as evidenced by their work on the \"Multimodal-RAG-Forge\" project. They focus on modularity, optimization (e.g., custom caching), and robustness (e.g., safe fallbacks) to address issues like latency and reliability.\\n\\n---\\n\\n### Communication Skills:\\nThe candidate demonstrated effective communication throughout the interview. Their responses were clear, well-articulated, and technically precise, making complex topics accessible.\\n\\n---\\n\\n### Relevant Experience Highlights:\\n- **Internship at Unihox:** Developed high-concurrency backends and AI-driven SaaS tools, reducing query handling time by 40%.\\n- **Multimodal-RAG-Forge Project:** Built a pipeline for text, video, and audio analysis, showcasing expertise in multimodal AI systems.\\n\\n---\\n\\n### Recommendations:\\nThe candidate is highly suitable for the AI Engineer role. Their technical skills, problem-solving abilities, and relevant experience make them a strong fit. I recommend proceeding to the next round of interviews.\\n\\n---\\n\\n**End of Report**### HR Interview Report: AI Engineer Position\\n\\n**Candidate Summary:**\\nThe candidate is a strong fit for the AI Engineer role at Data Solutions Inc. They demonstrated a solid academic foundation in Mathematics and Computing, complemented by practical experience in AI engineering, particularly in multimodal systems and MLOps. Their responses were technically sound, and they showcased problem-solving skills and a deep understanding of AI challenges.\\n\\n---\\n\\n### Strengths:\\n1. **Technical Expertise:** The candidate exhibited strong knowledge of AI systems, including multimodal pipelines, attention mechanisms, and Chain-of-Thought (CoT) prompting. Their explanation of the \"Multimodal-RAG-Forge\" project highlighted their ability to integrate fragmented data formats and optimize system performance.\\n2. **Problem-Solving Skills:** They effectively addressed challenges such as latency, API reliability, and semantic ambiguity, providing clear examples of solutions implemented in their projects.\\n3. **Relevant Experience:** Their internship at Unihox and academic background align well with the role, particularly their work on high-concurrency backends and AI-driven SaaS tools.\\n4. **Communication Skills:** The candidate communicated their ideas clearly and concisely, demonstrating the ability to explain complex technical concepts in an understandable manner.\\n\\n---\\n\\n### Areas for Development/Weaknesses:\\n1. **Structured Explanations:** While the candidate provided detailed responses, some explanations, such as the attention mechanism in transformers, could have been more structured and concise.\\n2. **Real-World Application Examples:** The candidate did not provide a specific example of applying CoT prompting in a real-world scenario, which would have strengthened their response.\\n\\n---\\n\\n### Key Technical Skills Demonstrated:\\n- **Programming Languages:** Python (implied from project descriptions).\\n- **AI/ML Frameworks:** LlamaIndex, Gemini, Whisper, MoviePy, Unstructured.\\n- **MLOps Tools:** MLflow, Docker.\\n- **Concepts:** Multimodal RAG, attention mechanisms, Chain-of-Thought prompting, high-concurrency backends.\\n\\n---\\n\\n### Problem-Solving Approach:\\nThe candidate approaches technical challenges methodically, as evidenced by their work on the \"Multimodal-RAG-Forge\" project. They focus on modularity, optimization (e.g., custom caching), and robustness (e.g., safe fallbacks) to address issues like latency and reliability.\\n\\n---\\n\\n### Communication Skills:\\nThe candidate demonstrated effective communication throughout the interview. Their responses were clear, well-articulated, and technically precise, making complex topics accessible.\\n\\n---\\n\\n### Relevant Experience Highlights:\\n- **Internship at Unihox:** Developed high-concurrency backends and AI-driven SaaS tools, reducing query handling time by 40%.\\n- **Multimodal-RAG-Forge Project:** Built a pipeline for text, video, and audio analysis, showcasing expertise in multimodal AI systems.\\n\\n---\\n\\n### Recommendations:\\nThe candidate is highly suitable for the AI Engineer role. Their technical skills, problem-solving abilities, and relevant experience make them a strong fit. I recommend proceeding to the next round of interviews.\\n\\n---\\n\\n**End of Report**',\n",
       " 'company_name': 'Data Solutions Inc.',\n",
       " 'messages': [HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}, id='acc24c24-1ac2-4fa5-ae82-6f479d4d7bd0'),\n",
       "  AIMessage(content=\"Hello! I'm your interviewer today from Data Solutions Inc. We're excited to have you here. To start, could you please introduce yourself briefly?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 535, 'total_tokens': 566, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'mistralai/devstral-2512:free', 'system_fingerprint': None, 'id': 'gen-1769336248-yv8injC7JrZC09hytAUs', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bf4a8-98c6-70f1-b616-e0461aa6c77c-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 535, 'output_tokens': 31, 'total_tokens': 566, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  HumanMessage(content=\"I am currently pursuing my M.Sc. in Mathematics & Computing at IIT (ISM) Dhanbad. My background in Mathematics gives me a strong foundation in Linear Algebra and Optimization, which I apply to building AI systems. Recently, I interned at Unihox as an AI Engineer, where I developed high-concurrency backends and AI-driven SaaS tools that reduced query handling time by 40%. I am passionate about the intersection of LLMs and MLOps, as seen in my project 'Multimodal-RAG-Forge,' where I built a pipeline for text, video, and audio analysis. I‚Äôm looking to bring this blend of mathematical rigor and engineering experience to a full-time role.\", additional_kwargs={}, response_metadata={}, id='adcc84e7-796a-4b4c-8da5-4b1aed6b492c'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 715, 'total_tokens': 739, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'mistralai/devstral-2512:free', 'system_fingerprint': None, 'id': 'gen-1769336293-EHqEwsEe1uvCrL959J8J', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019bf4a9-436d-7e73-a95c-d3f432a0c1c0-0', tool_calls=[{'name': 'candidate_resume_retriever', 'args': {'query': 'Multimodal-RAG-Forge'}, 'id': 'I3eVxOL2F', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 715, 'output_tokens': 24, 'total_tokens': 739, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  ToolMessage(content='Multimodal-RAG-Forge /gtb| LlamaIndex, LanceDB, Gemini, Unstructured, LangChain Dec 2025\\n‚Ä¢ Built an end-to-end multimodal RAG and OCR-based summarization system for documents containing text,\\ntables, images, audio, and video using LlamaIndex and Gemini.\\n‚Ä¢ Implemented preprocessing with Unstructured (OCR & table parsing), MoviePy (frames/audio), Whisper\\n(speech-to-text), and FastEmbed in a modular utility-based pipeline.\\n‚Ä¢ Added caching to skip redundant preprocessing (reducing 80‚Äì90% steps) and safe fallbacks to handle\\nOCR/LLM failures without pipeline crashes.\\nMedCoT-R1 FineTuner /gtb| PyTorch, LoRA, Transformers(HF), Unsloth, Weights & Biases Nov 2025\\n‚Ä¢ Designed a medical QA ‚ÄúAI Doctor‚Äù by fine-tuning DeepSeek-R1 (8B, 4-bit) with LoRA on a medical\\nchain-of-thought dataset.\\n‚Ä¢ Uses Unsloth + TRL SFTTrainer + Hugging Face with Weights & Biases for experiment tracking.\\n‚Ä¢ It nudges the model to follow a repeatable pattern (analyze ‚Üí decide) reducing random jumps to conclusions.\\n\\nEXPERIENCE\\nAI & Data Intern at Unihox /gtb Sep - Nov 2025\\nRole - AI Engineer (Remote)\\n‚Ä¢ Built an AI EDA agent for automated CSV analysis with 15+ exportable visualizations. Integrated\\nmultimodal AI with a local Llama-3.2-1B fallback for fast, reliable analysis under API limits.\\n‚Ä¢ Architected a high-concurrency FastAPI backend for a pan-India typing platform, integrating an AI coach\\nto deliver real-time feedback and analytics for 5,000+ exam aspirants.\\n‚Ä¢ Built FastAPI-based backend services for a healthcare middleware SaaS, integrating PostgreSQL and an\\nAI chatbot to streamline secure doctor‚Äìpatient workflows.\\n‚Ä¢ Engineered an AI-driven email marketing SaaS with WhatsApp chatbots and automated mailing pipelines,\\nreducing customer query handling time by 40%\\nPROJECTS\\nMultimodal-RAG-Forge /gtb| LlamaIndex, LanceDB, Gemini, Unstructured, LangChain Dec 2025\\n‚Ä¢ Built an end-to-end multimodal RAG and OCR-based summarization system for documents containing text,\\n\\nSudip Das\\nHowrah, West Bengal\\n/ne+918345077862 sudipd2004 Linkedin /gtbGithub /hackerrankHackerRank\\nEDUCATION\\nIndian Institute of Technology (ISM) Dhanbad 2024 ‚Äì 2026\\nM.Sc. - Mathematics & Computing - CGPA - 8.36 Dhanbad, Jharkhand\\nUniversity of Calcutta 2021 ‚Äì 2024\\nB.Sc.(Honours) - Mathematics - CGPA - 7.10 Howrah, West Bengal\\nTECHNICAL SKILLS\\nAI/ML : NLP, LLMs, RAG, Prompt Engineering, Computer Vision, Reinforcement Learning\\nFrameworks : Keras, PyTorch, LangChain/LangGraph, CrewAI, LlamaIndex, SHAP, HuggingFace, Groq\\nLanguages : Python (NumPy, Pandas, Seaborn), C++, C, SQL (MySQL, PostgreSQL)\\nCoursework : Statistics, Linear Algebra, Optimization, Data Mining, DBMS, Time Series, Neural Networks\\nMLOps & Tools : Git, GitHub, Kaggle, MLflow, Docker, FastAPI, Streamlit, Azure, n8n, MCP\\nEXPERIENCE\\nAI & Data Intern at Unihox /gtb Sep - Nov 2025\\nRole - AI Engineer (Remote)\\n‚Ä¢ Built an AI EDA agent for automated CSV analysis with 15+ exportable visualizations. Integrated\\n\\n‚Ä¢ It nudges the model to follow a repeatable pattern (analyze ‚Üí decide) reducing random jumps to conclusions.\\nML-Powered SatisFlight Engine /gtb| Kaggle, GitHub, DagsHub, DVC, Scikit-Learn, XGBoost Sep 2025\\n‚Ä¢ Developed an end-to-end ML prediction pipeline on Airlines Customer Satisfaction data from Kaggle.\\n‚Ä¢ Implemented full ML workflow with SHAP-based interpretability with Accuracy: 95.56%, F1-score: 94.87%\\n‚Ä¢ Integrated CI/CD, version control, and experiment tracking using MLflow, and deployed via Docker.\\nCERTIFICATIONS\\n‚Ä¢ AI & Machine Learning ‚Äî SimpliLearn\\n‚Ä¢ SQL ‚Äî HackerRank ‚Äî‚Äî July, 2025\\n‚Ä¢ Edge AI Workflow Design ‚Äî CILCII, IIT(ISM) DHANBAD ‚Äî‚Äî March, 2025\\nAchievements & Honors\\n‚àóCleared IIT JAM Examination, 2024 (AIR 500) & College Topper in Graduation.\\n‚àó 2nd Position in State-Level Quiz Competition, 2021.\\n‚àó HackerRank: 5 star (Gold) in Python & SQL and Active competitive programmer on Codeforces.', name='candidate_resume_retriever', id='40eb16bc-db61-40b3-ae0d-487a922c45cb', tool_call_id='I3eVxOL2F'),\n",
       "  AIMessage(content='tool used: `candidate_resume_retriever`\\n\\nThank you for the introduction! I noticed your project \"Multimodal-RAG-Forge\" on your resume. Could you tell me more about the challenges you faced while building this multimodal RAG and OCR-based summarization system and how you overcame them?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 1883, 'total_tokens': 1952, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'mistralai/devstral-2512:free', 'system_fingerprint': None, 'id': 'gen-1769336295-KIcSecHkhUz82UHYGkix', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bf4a9-5175-7c41-bbef-1655d57af829-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 1883, 'output_tokens': 69, 'total_tokens': 1952, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  HumanMessage(content='Building this system required synchronizing fragmented data formats like tables, audio, and video into a unified context window using LlamaIndex and Gemini. To handle the integration, I architected a modular pipeline that used Unstructured for table parsing, MoviePy for video frames, and Whisper for speech-to-text, ensuring every medium was searchable. One of the biggest challenges was high latency and API reliability, which I solved by implementing a custom caching layer that skipped 80-90% of redundant preprocessing steps and adding safe fallbacks to prevent pipeline crashes. I specifically focused on preserving structural data from tables rather than flattening it, allowing for high-fidelity summarization across different data types. Ultimately, this project demonstrated my ability to build robust, multimodal AI infrastructure that goes beyond simple text-based retrieval.', additional_kwargs={}, response_metadata={}, id='2cffc596-af80-4e4b-95e0-b25e80fcc627'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 2117, 'total_tokens': 2135, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'mistralai/devstral-2512:free', 'system_fingerprint': None, 'id': 'gen-1769336351-CK8y2YkrkbmTj2OwI1jQ', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019bf4aa-2c9e-7b90-8c3d-89225c928a5a-0', tool_calls=[{'name': 'interview_document_retriever', 'args': {'query': 'AI Engineer position'}, 'id': 'EIY2zLNuU', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 2117, 'output_tokens': 18, 'total_tokens': 2135, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  ToolMessage(content='Top 50 Large Language Model (LLM) Interview\\nQuestions\\nHao Hoang - Follow me on LinkedIn for AI insights!\\nMay 2025\\nExplore the key concepts, techniques, and challenges of Large Language Models (LLMs)\\nwith this comprehensive guide, crafted for AI enthusiasts and professionals preparing for\\ninterviews.\\nIntroduction\\nLarge Language Models (LLMs) are revolutionizing artiÔ¨Åcial intelligence, enabling ap-\\nplications from chatbots to automated content creation. This document compiles 50\\nessential interview questions, carefully curated to deepen your understanding of LLMs.\\nEach question is paired with a detailed answer, blending technical insights with practical\\nexamples. Share this knowledge with your network to spark meaningful discussions in\\nthe AI community!\\n1 Question 1: What does tokenization entail, and why is it\\ncritical for LLMs?\\nTokenization involves breaking down text into smaller units, or tokens, such as words,\\n\\n49 Question 49: What deÔ¨Ånes a Large Language Model (LLM)?\\nLLMs are AI systems trained on vast text corpora to understand and generate human-like\\nlanguage. With billions of parameters, they excel in tasks like translation, summarization,\\nand question answering, leveraging contextual learning for broad applicability.\\n50 Question 50: What challenges do LLMs face in deployment?\\nLLM challenges include:\\n‚Ä¢ Resource Intensity: High computational demands.\\n‚Ä¢ Bias: Risk of perpetuating training data biases.\\n‚Ä¢ Interpretability: Complex models are hard to explain.\\n‚Ä¢ Privacy: Potential data security concerns.\\nAddressing these ensures ethical and eÔ¨Äective LLM use.\\nConclusion\\nThis guide equips you with in-depth knowledge of LLMs, from core concepts to advanced\\ntechniques. Share it with your LinkedIn community to inspire and educate aspiring AI\\nprofessionals. For more AI/ML insights, connect with me at Your LinkedIn ProÔ¨Åle .\\n12\\n\\nthe AI community!\\n1 Question 1: What does tokenization entail, and why is it\\ncritical for LLMs?\\nTokenization involves breaking down text into smaller units, or tokens, such as words,\\nsubwords, or characters. For example, \"artiÔ¨Åcial\" might be split into \"art,\" \"iÔ¨Åc,\" and\\n\"ial.\" This process is vital because LLMs process numerical representations of tokens,\\nnot raw text. Tokenization enables models to handle diverse languages, manage rare or\\nunknown words, and optimize vocabulary size, enhancing computational eÔ¨Éciency and\\nmodel performance.\\n2 Question 2: How does the attention mechanism function in\\ntransformer models?\\nThe attention mechanism allows LLMs to weigh the importance of diÔ¨Äerent tokens in a se-\\nquence when generating or interpreting text. It computes similarity scores between query,\\nkey, and value vectors, using operations like dot products, to focus on relevant tokens.\\nFor instance, in \"The cat chased the mouse,\" attention helps the model link \"mouse\" to\\n\\nRAG involves:\\n1. Retrieval: Fetching relevant documents using query embeddings.\\n2. Ranking: Sorting documents by relevance.\\n3. Generation: Using retrieved context to generate accurate responses.\\nRAG enhances factual accuracy in tasks like question answering.\\n37 Question 37: How does Mixture of Experts (MoE) enhance\\nLLM scalability?\\nMoE uses a gating function to activate speciÔ¨Åc expert sub-networks per input, reducing\\ncomputational load. For example, only 10% of a models parameters might be used per\\nquery, enabling billion-parameter models to operate eÔ¨Éciently while maintaining high\\nperformance.\\n38 Question 38: What is Chain-of-Thought (CoT) prompting,\\nand how does it aid reasoning?\\nCoT prompting guides LLMs to solve problems step-by-step, mimicking human reasoning.\\nFor example, in math problems, it breaks down calculations into logical steps, improving\\n9', name='interview_document_retriever', id='7993581b-cf8b-4880-acda-5378f3f4418f', tool_call_id='EIY2zLNuU'),\n",
       "  AIMessage(content='tool used: `interview_document_retriever`\\n\\nQuestion one: What challenges do LLMs face in deployment?\\n\\nQuestion two: How does the attention mechanism function in transformer models?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 2970, 'total_tokens': 3008, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'mistralai/devstral-2512:free', 'system_fingerprint': None, 'id': 'gen-1769336354-xqfpqYn2PJ5juXGtVNtv', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bf4aa-3890-7f63-897a-a3c14b357f9f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 2970, 'output_tokens': 38, 'total_tokens': 3008, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  HumanMessage(content='Deploying LLMs involves significant hurdles, primarily computational costs and latency, as these models require expensive GPU resources to provide real-time responses. Reliability is another major issue, where models may \"hallucinate\" or provide inconsistent results under API limits, a challenge you addressed in your internship by implementing local fallbacks like Llama-3.2-1B. Furthermore, managing data security and high-concurrency for thousands of simultaneous users requires robust backend architectures, similar to the FastAPI systems you built for healthcare and typing platforms. Finally, maintaining model accuracy over time requires complex MLOps pipelines for versioning and experiment tracking using tools like MLflow or Docker', additional_kwargs={}, response_metadata={}, id='7fe3e6f8-db53-4947-9299-8fb46acea441'),\n",
       "  AIMessage(content=\"Thank you for the detailed response. Let's move on to the next question.\\n\\nQuestion one: How does the attention mechanism function in transformer models?\\n\\nQuestion two: Can you explain how you would optimize the attention mechanism for efficiency in a real-world application?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 3145, 'total_tokens': 3196, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'mistralai/devstral-2512:free', 'system_fingerprint': None, 'id': 'gen-1769336451-woRVXIstUJJpG5tmXheY', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bf4ab-ad72-7831-8411-5b54755fa71d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 3145, 'output_tokens': 51, 'total_tokens': 3196, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  HumanMessage(content='The attention mechanism can struggle with semantic ambiguity when words have multiple meanings that depend on subtle, external, or long-distance context. In a sentence like \"The bank was closed,\" the model might fail to distinguish between a financial institution and a riverbank if the preceding sentences are missing or equally vague. For ambiguous references (anaphora), such as \"The trophy didn\\'t fit into the brown suitcase because it was too large,\" the mechanism may incorrectly attend to \"suitcase\" instead of \"trophy\" if the training data hasn\\'t sufficiently captured the physical logic of sizes. Furthermore, as sequence length increases, the \"signal\" of a relevant token can get diluted by the \"noise\" of many irrelevant tokens, leading to a loss of focus.', additional_kwargs={}, response_metadata={}, id='25311647-f640-4769-9431-799a743762d3'),\n",
       "  AIMessage(content=\"Thank you for the detailed explanation. Let's move on to the next question.\\n\\nQuestion one: What is Chain-of-Thought (CoT) prompting, and how does it aid reasoning?\\n\\nQuestion two: Can you provide an example of how you might apply CoT prompting in a real-world scenario?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 3350, 'total_tokens': 3411, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'mistralai/devstral-2512:free', 'system_fingerprint': None, 'id': 'gen-1769336577-3BiYNCbBIRUtUDsAnRUY', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bf4ad-9aab-7a22-be4e-290e8cacec74-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 3350, 'output_tokens': 61, 'total_tokens': 3411, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  HumanMessage(content='Chain-of-Thought (CoT) prompting is a technique that encourages Large Language Models to decompose complex problems into a series of intermediate logical steps before arriving at a final answer. By explicitly modeling the \"reasoning path,\" it allows the model to allocate more compute to difficult tasks and reduces the likelihood of logical \"hallucinations\" or random jumps to conclusions. It essentially shifts the model from simple pattern matching to a structured \"analyze ‚Üí decide\" workflow, significantly improving performance on mathematical and commonsense reasoning tasks.', additional_kwargs={}, response_metadata={}, id='9232c761-57fe-48d6-9dad-36c1d96090d3'),\n",
       "  AIMessage(content=\"Thank you, that's it for today.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 3518, 'total_tokens': 3528, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'mistralai/devstral-2512:free', 'system_fingerprint': None, 'id': 'gen-1769336658-Z3OfLrALinj3Sd23d4jJ', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bf4ae-d88e-7921-b229-1caf6d531f2b-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 3518, 'output_tokens': 10, 'total_tokens': 3528, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  AIMessage(content='Evaluation:\\n1. **Introduction question: 9/10** - The candidate provided a clear and concise introduction, highlighting their academic background, relevant skills (Linear Algebra, Optimization), and practical experience (internship at Unihox). They also mentioned their passion for AI and a specific project, demonstrating alignment with the role.\\n\\n2. **Project question: 9/10** - The candidate explained the challenges faced in the \"Multimodal-RAG-Forge\" project in detail, including technical solutions like modular pipelines, custom caching, and handling latency. Their response demonstrated problem-solving skills and a deep understanding of the project.\\n\\n3. **Technical question one (Challenges in LLM deployment): 8/10** - The candidate addressed key challenges such as computational costs, latency, reliability, and data security. They also tied their response to real-world solutions like local fallbacks and MLOps tools, showing practical knowledge.\\n\\n4. **Technical question two (Attention mechanism in transformers): 7/10** - The candidate discussed semantic ambiguity and the limitations of the attention mechanism, such as handling ambiguous references and long sequences. However, the response could have been more structured and included a clearer explanation of how the attention mechanism functions.\\n\\n5. **Technical question one (Chain-of-Thought prompting): 8/10** - The candidate provided a clear definition of CoT prompting and explained its benefits in improving reasoning and reducing hallucinations. The response was relevant and demonstrated understanding.\\n\\n6. **Technical question two (Application of CoT prompting): N/A** - The candidate did not provide an example of applying CoT prompting in a real-world scenario, so this part could not be evaluated.', additional_kwargs={}, response_metadata={}, id='3f6b63c2-3314-4196-8aa2-b0c80668b1f1', tool_calls=[], invalid_tool_calls=[]),\n",
       "  AIMessage(content='### HR Interview Report: AI Engineer Position\\n**Candidate Summary:**\\nThe candidate is a strong fit for the AI Engineer role at Data Solutions Inc. They demonstrated a solid academic foundation in Mathematics and Computing, complemented by practical experience in AI engineering, particularly in multimodal systems and MLOps. Their responses were technically sound, and they showcased problem-solving skills and a deep understanding of AI challenges.\\n\\n---\\n\\n### Strengths:\\n1. **Technical Expertise:** The candidate exhibited strong knowledge of AI systems, including multimodal pipelines, attention mechanisms, and Chain-of-Thought (CoT) prompting. Their explanation of the \"Multimodal-RAG-Forge\" project highlighted their ability to integrate fragmented data formats and optimize system performance.\\n2. **Problem-Solving Skills:** They effectively addressed challenges such as latency, API reliability, and semantic ambiguity, providing clear examples of solutions implemented in their projects.\\n3. **Relevant Experience:** Their internship at Unihox and academic background align well with the role, particularly their work on high-concurrency backends and AI-driven SaaS tools.\\n4. **Communication Skills:** The candidate communicated their ideas clearly and concisely, demonstrating the ability to explain complex technical concepts in an understandable manner.\\n\\n---\\n\\n### Areas for Development/Weaknesses:\\n1. **Structured Explanations:** While the candidate provided detailed responses, some explanations, such as the attention mechanism in transformers, could have been more structured and concise.\\n2. **Real-World Application Examples:** The candidate did not provide a specific example of applying CoT prompting in a real-world scenario, which would have strengthened their response.\\n\\n---\\n\\n### Key Technical Skills Demonstrated:\\n- **Programming Languages:** Python (implied from project descriptions).\\n- **AI/ML Frameworks:** LlamaIndex, Gemini, Whisper, MoviePy, Unstructured.\\n- **MLOps Tools:** MLflow, Docker.\\n- **Concepts:** Multimodal RAG, attention mechanisms, Chain-of-Thought prompting, high-concurrency backends.\\n\\n---\\n\\n### Problem-Solving Approach:\\nThe candidate approaches technical challenges methodically, as evidenced by their work on the \"Multimodal-RAG-Forge\" project. They focus on modularity, optimization (e.g., custom caching), and robustness (e.g., safe fallbacks) to address issues like latency and reliability.\\n\\n---\\n\\n### Communication Skills:\\nThe candidate demonstrated effective communication throughout the interview. Their responses were clear, well-articulated, and technically precise, making complex topics accessible.\\n\\n---\\n\\n### Relevant Experience Highlights:\\n- **Internship at Unihox:** Developed high-concurrency backends and AI-driven SaaS tools, reducing query handling time by 40%.\\n- **Multimodal-RAG-Forge Project:** Built a pipeline for text, video, and audio analysis, showcasing expertise in multimodal AI systems.\\n\\n---\\n\\n### Recommendations:\\nThe candidate is highly suitable for the AI Engineer role. Their technical skills, problem-solving abilities, and relevant experience make them a strong fit. I recommend proceeding to the next round of interviews.\\n\\n---\\n\\n**End of Report**', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1368, 'prompt_tokens': 2179, 'total_tokens': 3547, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'mistralai/devstral-2512:free', 'system_fingerprint': None, 'id': 'gen-1769336725-oOyTVlUJUPfAEcqCEhvs', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019bf4af-e08b-7c60-9e5c-051a25ad2bd1-0', tool_calls=[{'name': 'save_report_as_pdf', 'args': {'report_content': '# HR Interview Report: AI Engineer Position\\n\\n**Candidate Summary:**\\nThe candidate is a strong fit for the AI Engineer role at Data Solutions Inc. They demonstrated a solid academic foundation in Mathematics and Computing, complemented by practical experience in AI engineering, particularly in multimodal systems and MLOps. Their responses were technically sound, and they showcased problem-solving skills and a deep understanding of AI challenges.\\n\\n---\\n\\n### Strengths:\\n1. **Technical Expertise:** The candidate exhibited strong knowledge of AI systems, including multimodal pipelines, attention mechanisms, and Chain-of-Thought (CoT) prompting. Their explanation of the \"Multimodal-RAG-Forge\" project highlighted their ability to integrate fragmented data formats and optimize system performance.\\n2. **Problem-Solving Skills:** They effectively addressed challenges such as latency, API reliability, and semantic ambiguity, providing clear examples of solutions implemented in their projects.\\n3. **Relevant Experience:** Their internship at Unihox and academic background align well with the role, particularly their work on high-concurrency backends and AI-driven SaaS tools.\\n4. **Communication Skills:** The candidate communicated their ideas clearly and concisely, demonstrating the ability to explain complex technical concepts in an understandable manner.\\n\\n---\\n\\n### Areas for Development/Weaknesses:\\n1. **Structured Explanations:** While the candidate provided detailed responses, some explanations, such as the attention mechanism in transformers, could have been more structured and concise.\\n2. **Real-World Application Examples:** The candidate did not provide a specific example of applying CoT prompting in a real-world scenario, which would have strengthened their response.\\n\\n---\\n\\n### Key Technical Skills Demonstrated:\\n- **Programming Languages:** Python (implied from project descriptions).\\n- **AI/ML Frameworks:** LlamaIndex, Gemini, Whisper, MoviePy, Unstructured.\\n- **MLOps Tools:** MLflow, Docker.\\n- **Concepts:** Multimodal RAG, attention mechanisms, Chain-of-Thought prompting, high-concurrency backends.\\n\\n---\\n\\n### Problem-Solving Approach:\\nThe candidate approaches technical challenges methodically, as evidenced by their work on the \"Multimodal-RAG-Forge\" project. They focus on modularity, optimization (e.g., custom caching), and robustness (e.g., safe fallbacks) to address issues like latency and reliability.\\n\\n---\\n\\n### Communication Skills:\\nThe candidate demonstrated effective communication throughout the interview. Their responses were clear, well-articulated, and technically precise, making complex topics accessible.\\n\\n---\\n\\n### Relevant Experience Highlights:\\n- **Internship at Unihox:** Developed high-concurrency backends and AI-driven SaaS tools, reducing query handling time by 40%.\\n- **Multimodal-RAG-Forge Project:** Built a pipeline for text, video, and audio analysis, showcasing expertise in multimodal AI systems.\\n\\n---\\n\\n### Recommendations:\\nThe candidate is highly suitable for the AI Engineer role. Their technical skills, problem-solving abilities, and relevant experience make them a strong fit. I recommend proceeding to the next round of interviews.\\n\\n---\\n\\n**End of Report**', 'filename': 'Interview_Report_Data Solutions Inc._AI Engineer.pdf'}, 'id': 'diVGFNQMV', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 2179, 'output_tokens': 1368, 'total_tokens': 3547, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  ToolMessage(content='Report successfully saved to: c:\\\\Users\\\\Sudip Das\\\\SudipWorkspace\\\\Projects\\\\LangInterview\\\\notebooks\\\\Interview_Report_Data Solutions Inc._AI Engineer.pdf', name='save_report_as_pdf', id='dfb0d4dc-6081-43b3-8e4b-234160f6458f', tool_call_id='diVGFNQMV'),\n",
       "  HumanMessage(content='can you give some feedback ?', additional_kwargs={}, response_metadata={}, id='f81e5055-9172-4e10-a750-bac75ec6dd63'),\n",
       "  AIMessage(content='Certainly! Here‚Äôs a structured feedback based on your performance in the interview:\\n\\n---\\n\\n### **Strengths:**\\n1. **Technical Depth:**\\n   - You demonstrated a strong understanding of AI concepts, particularly in multimodal systems, RAG pipelines, and MLOps. Your explanation of the \"Multimodal-RAG-Forge\" project was detailed and showcased your ability to tackle complex challenges like latency and API reliability.\\n   - Your knowledge of Chain-of-Thought (CoT) prompting and attention mechanisms was evident, and you tied these concepts to real-world applications effectively.\\n\\n2. **Problem-Solving Skills:**\\n   - You provided clear examples of how you addressed challenges in your projects, such as implementing custom caching to reduce preprocessing steps and using safe fallbacks to handle OCR/LLM failures. This highlights your ability to think critically and optimize systems.\\n\\n3. **Relevant Experience:**\\n   - Your internship at Unihox and your academic background in Mathematics and Computing align well with the AI Engineer role. Your work on high-concurrency backends and AI-driven SaaS tools demonstrates practical experience that is valuable for this position.\\n\\n4. **Communication:**\\n   - You articulated your thoughts clearly and concisely, making complex technical concepts understandable. This is a crucial skill for collaborating with teams and stakeholders.\\n\\n---\\n\\n### **Areas for Improvement:**\\n1. **Structured Responses:**\\n   - While your explanations were detailed, some responses could have been more structured. For example, when discussing the attention mechanism in transformers, breaking down the explanation into smaller, logical steps would have made it easier to follow.\\n\\n2. **Real-World Examples:**\\n   - For questions like applying CoT prompting in a real-world scenario, providing a concrete example would have strengthened your response. This helps interviewers visualize how you would implement solutions in practice.\\n\\n3. **Conciseness:**\\n   - At times, your responses were slightly verbose. Practicing concise answers while retaining key details can make your communication even more effective, especially in time-sensitive interview settings.\\n\\n---\\n\\n### **Specific Feedback on Responses:**\\n1. **Multimodal-RAG-Forge Project:**\\n   - **Strength:** You did an excellent job explaining the challenges and solutions, such as modular pipelines and caching. This showcased your hands-on experience and problem-solving skills.\\n   - **Improvement:** You could have briefly mentioned the impact of these solutions (e.g., performance metrics or user feedback) to quantify your success.\\n\\n2. **LLM Deployment Challenges:**\\n   - **Strength:** You covered key challenges like computational costs, latency, and reliability, and tied them to your experience with local fallbacks and MLOps tools.\\n   - **Improvement:** You could have expanded on how you specifically addressed these challenges in your projects, such as tools or methodologies used.\\n\\n3. **Attention Mechanism:**\\n   - **Strength:** You discussed semantic ambiguity and the limitations of attention mechanisms, showing a deep understanding of the topic.\\n   - **Improvement:** A clearer explanation of how the attention mechanism functions (e.g., query, key, value vectors) would have made your response more comprehensive.\\n\\n4. **Chain-of-Thought Prompting:**\\n   - **Strength:** You provided a clear definition of CoT prompting and its benefits.\\n   - **Improvement:** Adding an example of how you applied CoT prompting in a project or hypothetical scenario would have made your response more impactful.\\n\\n---\\n\\n### **Overall Impression:**\\nYou are a strong candidate for the AI Engineer role, with a solid foundation in AI/ML concepts, practical experience, and effective communication skills. With minor improvements in structuring your responses and providing real-world examples, you can further enhance your interview performance.\\n\\n---\\n\\n### **Recommendations for Future Interviews:**\\n1. **Practice Structured Responses:** Use frameworks like STAR (Situation, Task, Action, Result) to organize your answers, especially for behavioral or project-related questions.\\n2. **Prepare Examples:** Think of specific examples where you applied technical concepts (e.g., CoT prompting) in your projects or internships.\\n3. **Mock Interviews:** Conduct mock interviews to refine your conciseness and clarity. Focus on delivering key points succinctly while retaining depth.\\n\\n---\\n\\nKeep up the great work, and best of luck in your future interviews! Let me know if you\\'d like to discuss any of this feedback further.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 897, 'prompt_tokens': 5296, 'total_tokens': 6193, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'mistralai/devstral-2512:free', 'system_fingerprint': None, 'id': 'gen-1769336799-cyHd3Ga6WzzEYRq3HJJF', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bf4b0-ff1c-7ea0-95ed-2b643c766409-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 5296, 'output_tokens': 897, 'total_tokens': 6193, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  HumanMessage(content='no question', additional_kwargs={}, response_metadata={}, id='71d062e1-57af-462e-b6ea-45be13f3d05d'),\n",
       "  AIMessage(content=\"Thank you, that's it for today.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 6197, 'total_tokens': 6207, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'mistralai/devstral-2512:free', 'system_fingerprint': None, 'id': 'gen-1769336952-m5BJUz5T6ezKh2SEZou3', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bf4b3-513b-71a0-89b9-1c527e34ce4d-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 6197, 'output_tokens': 10, 'total_tokens': 6207, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  AIMessage(content='Evaluation:\\n1. **Introduction question: 9/10** - The candidate provided a clear and concise introduction, highlighting their academic background, relevant skills (Linear Algebra, Optimization), and practical experience (internship at Unihox). They also mentioned their passion for AI and a specific project, demonstrating alignment with the role.\\n\\n2. **Project question: 9/10** - The candidate explained the challenges faced in the \"Multimodal-RAG-Forge\" project in detail, including technical solutions like modular pipelines, custom caching, and handling latency. Their response demonstrated problem-solving skills and a deep understanding of the project.\\n\\n3. **Technical question one (Challenges in LLM deployment): 8/10** - The candidate addressed key challenges such as computational costs, latency, reliability, and data security. They also tied their response to real-world solutions like local fallbacks and MLOps tools, showing practical knowledge.\\n\\n4. **Technical question two (Attention mechanism in transformers): 7/10** - The candidate discussed semantic ambiguity and the limitations of the attention mechanism, such as handling ambiguous references and long sequences. However, the response could have been more structured and included a clearer explanation of how the attention mechanism functions.\\n\\n5. **Technical question one (Chain-of-Thought prompting): 8/10** - The candidate provided a clear definition of CoT prompting and explained its benefits in improving reasoning and reducing hallucinations. The response was relevant and demonstrated understanding.\\n\\n6. **Technical question two (Application of CoT prompting): N/A** - The candidate did not provide an example of applying CoT prompting in a real-world scenario, so this part could not be evaluated.', additional_kwargs={}, response_metadata={}, id='43119289-f4ef-4524-9220-aae553c28c86', tool_calls=[], invalid_tool_calls=[]),\n",
       "  AIMessage(content='### HR Interview Report: AI Engineer Position\\n\\n**Candidate Summary:**\\nThe candidate is a strong fit for the AI Engineer role at Data Solutions Inc. They demonstrated a solid academic foundation in Mathematics and Computing, complemented by practical experience in AI engineering, particularly in multimodal systems and MLOps. Their responses were technically sound, and they showcased problem-solving skills and a deep understanding of AI challenges.\\n\\n---\\n\\n### Strengths:\\n1. **Technical Expertise:** The candidate exhibited strong knowledge of AI systems, including multimodal pipelines, attention mechanisms, and Chain-of-Thought (CoT) prompting. Their explanation of the \"Multimodal-RAG-Forge\" project highlighted their ability to integrate fragmented data formats and optimize system performance.\\n2. **Problem-Solving Skills:** They effectively addressed challenges such as latency, API reliability, and semantic ambiguity, providing clear examples of solutions implemented in their projects.\\n3. **Relevant Experience:** Their internship at Unihox and academic background align well with the role, particularly their work on high-concurrency backends and AI-driven SaaS tools.\\n4. **Communication Skills:** The candidate communicated their ideas clearly and concisely, demonstrating the ability to explain complex technical concepts in an understandable manner.\\n\\n---\\n\\n### Areas for Development/Weaknesses:\\n1. **Structured Explanations:** While the candidate provided detailed responses, some explanations, such as the attention mechanism in transformers, could have been more structured and concise.\\n2. **Real-World Application Examples:** The candidate did not provide a specific example of applying CoT prompting in a real-world scenario, which would have strengthened their response.\\n\\n---\\n\\n### Key Technical Skills Demonstrated:\\n- **Programming Languages:** Python (implied from project descriptions).\\n- **AI/ML Frameworks:** LlamaIndex, Gemini, Whisper, MoviePy, Unstructured.\\n- **MLOps Tools:** MLflow, Docker.\\n- **Concepts:** Multimodal RAG, attention mechanisms, Chain-of-Thought prompting, high-concurrency backends.\\n\\n---\\n\\n### Problem-Solving Approach:\\nThe candidate approaches technical challenges methodically, as evidenced by their work on the \"Multimodal-RAG-Forge\" project. They focus on modularity, optimization (e.g., custom caching), and robustness (e.g., safe fallbacks) to address issues like latency and reliability.\\n\\n---\\n\\n### Communication Skills:\\nThe candidate demonstrated effective communication throughout the interview. Their responses were clear, well-articulated, and technically precise, making complex topics accessible.\\n\\n---\\n\\n### Relevant Experience Highlights:\\n- **Internship at Unihox:** Developed high-concurrency backends and AI-driven SaaS tools, reducing query handling time by 40%.\\n- **Multimodal-RAG-Forge Project:** Built a pipeline for text, video, and audio analysis, showcasing expertise in multimodal AI systems.\\n\\n---\\n\\n### Recommendations:\\nThe candidate is highly suitable for the AI Engineer role. Their technical skills, problem-solving abilities, and relevant experience make them a strong fit. I recommend proceeding to the next round of interviews.\\n\\n---\\n\\n**End of Report**', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1368, 'prompt_tokens': 4109, 'total_tokens': 5477, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'cost': 0, 'is_byok': False, 'cost_details': {'upstream_inference_cost': 0, 'upstream_inference_prompt_cost': 0, 'upstream_inference_completions_cost': 0}}, 'model_provider': 'openai', 'model_name': 'mistralai/devstral-2512:free', 'system_fingerprint': None, 'id': 'gen-1769336958-AVglaJmR1yFVB7jzqKWZ', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019bf4b3-7034-7122-a896-fcb165fec8e6-0', tool_calls=[{'name': 'save_report_as_pdf', 'args': {'report_content': '# HR Interview Report: AI Engineer Position\\n\\n**Candidate Summary:**\\nThe candidate is a strong fit for the AI Engineer role at Data Solutions Inc. They demonstrated a solid academic foundation in Mathematics and Computing, complemented by practical experience in AI engineering, particularly in multimodal systems and MLOps. Their responses were technically sound, and they showcased problem-solving skills and a deep understanding of AI challenges.\\n\\n---\\n\\n### Strengths:\\n1. **Technical Expertise:** The candidate exhibited strong knowledge of AI systems, including multimodal pipelines, attention mechanisms, and Chain-of-Thought (CoT) prompting. Their explanation of the \"Multimodal-RAG-Forge\" project highlighted their ability to integrate fragmented data formats and optimize system performance.\\n2. **Problem-Solving Skills:** They effectively addressed challenges such as latency, API reliability, and semantic ambiguity, providing clear examples of solutions implemented in their projects.\\n3. **Relevant Experience:** Their internship at Unihox and academic background align well with the role, particularly their work on high-concurrency backends and AI-driven SaaS tools.\\n4. **Communication Skills:** The candidate communicated their ideas clearly and concisely, demonstrating the ability to explain complex technical concepts in an understandable manner.\\n\\n---\\n\\n### Areas for Development/Weaknesses:\\n1. **Structured Explanations:** While the candidate provided detailed responses, some explanations, such as the attention mechanism in transformers, could have been more structured and concise.\\n2. **Real-World Application Examples:** The candidate did not provide a specific example of applying CoT prompting in a real-world scenario, which would have strengthened their response.\\n\\n---\\n\\n### Key Technical Skills Demonstrated:\\n- **Programming Languages:** Python (implied from project descriptions).\\n- **AI/ML Frameworks:** LlamaIndex, Gemini, Whisper, MoviePy, Unstructured.\\n- **MLOps Tools:** MLflow, Docker.\\n- **Concepts:** Multimodal RAG, attention mechanisms, Chain-of-Thought prompting, high-concurrency backends.\\n\\n---\\n\\n### Problem-Solving Approach:\\nThe candidate approaches technical challenges methodically, as evidenced by their work on the \"Multimodal-RAG-Forge\" project. They focus on modularity, optimization (e.g., custom caching), and robustness (e.g., safe fallbacks) to address issues like latency and reliability.\\n\\n---\\n\\n### Communication Skills:\\nThe candidate demonstrated effective communication throughout the interview. Their responses were clear, well-articulated, and technically precise, making complex topics accessible.\\n\\n---\\n\\n### Relevant Experience Highlights:\\n- **Internship at Unihox:** Developed high-concurrency backends and AI-driven SaaS tools, reducing query handling time by 40%.\\n- **Multimodal-RAG-Forge Project:** Built a pipeline for text, video, and audio analysis, showcasing expertise in multimodal AI systems.\\n\\n---\\n\\n### Recommendations:\\nThe candidate is highly suitable for the AI Engineer role. Their technical skills, problem-solving abilities, and relevant experience make them a strong fit. I recommend proceeding to the next round of interviews.\\n\\n---\\n\\n**End of Report**', 'filename': 'Interview_Report_Data Solutions Inc._AI Engineer.pdf'}, 'id': 'YFYHeTTdN', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 4109, 'output_tokens': 1368, 'total_tokens': 5477, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       "  ToolMessage(content='Report successfully saved to: c:\\\\Users\\\\Sudip Das\\\\SudipWorkspace\\\\Projects\\\\LangInterview\\\\notebooks\\\\Interview_Report_Data Solutions Inc._AI Engineer.pdf', name='save_report_as_pdf', id='cde10c0f-007a-4b3d-a7ed-953f27882bc0', tool_call_id='YFYHeTTdN')]}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaaf2b3",
   "metadata": {},
   "source": [
    "# **Sound System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a42245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    mode: str\n",
    "    num_of_q: int\n",
    "    num_of_follow_up: int\n",
    "    position: str\n",
    "    evaluation_result: str | None\n",
    "    company_name: str\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b15e92",
   "metadata": {},
   "source": [
    "### **TTS with gtts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12df67bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ApiError",
     "evalue": "headers: {'date': 'Thu, 29 Jan 2026 11:30:59 GMT', 'server': 'uvicorn', 'content-length': '476', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'access-control-allow-headers': '*', 'access-control-allow-methods': 'POST, PATCH, OPTIONS, DELETE, GET, PUT', 'access-control-max-age': '600', 'strict-transport-security': 'max-age=1800;', 'x-trace-id': '0ef2054edfd70d97207f6d65958bb2af', 'x-region': 'asia-southeast1', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 401, body: {'detail': {'status': 'detected_unusual_activity', 'message': 'Unusual activity detected. Free Tier usage disabled. If you are using a proxy/VPN you might need to purchase a Paid Plan to not trigger our abuse detectors. Free Tier only works if users do not abuse it, for example by creating multiple free accounts. If we notice that many people try to abuse it, we will need to reconsider Free Tier altogether. \\nPlease play fair and purchase any Paid Subscription to continue.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mApiError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Save to a file by iterating through the generator\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mout.mp3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maudio_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Play in notebook\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sudip Das\\SudipWorkspace\\Projects\\LangInterview\\myenv\\Lib\\site-packages\\elevenlabs\\text_to_speech\\client.py:157\u001b[39m, in \u001b[36mTextToSpeechClient.convert\u001b[39m\u001b[34m(self, voice_id, text, enable_logging, optimize_streaming_latency, output_format, model_id, language_code, voice_settings, pronunciation_dictionary_locators, seed, previous_text, next_text, previous_request_ids, next_request_ids, use_pvc_as_ivc, apply_text_normalization, apply_language_text_normalization, request_options)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(\n\u001b[32m     49\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     50\u001b[39m     voice_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m     request_options: typing.Optional[RequestOptions] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     71\u001b[39m ) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m     72\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[33;03m    Converts text into speech using a voice of your choice and returns audio.\u001b[39;00m\n\u001b[32m     74\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    155\u001b[39m \u001b[33;03m    )\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvoice_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable_logging\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimize_streaming_latency\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize_streaming_latency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlanguage_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlanguage_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvoice_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvoice_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpronunciation_dictionary_locators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpronunciation_dictionary_locators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprevious_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprevious_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnext_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnext_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprevious_request_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprevious_request_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnext_request_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnext_request_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_pvc_as_ivc\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_pvc_as_ivc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapply_text_normalization\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapply_text_normalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapply_language_text_normalization\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapply_language_text_normalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sudip Das\\SudipWorkspace\\Projects\\LangInterview\\myenv\\Lib\\site-packages\\elevenlabs\\text_to_speech\\raw_client.py:204\u001b[39m, in \u001b[36mRawTextToSpeechClient.convert\u001b[39m\u001b[34m(self, voice_id, text, enable_logging, optimize_streaming_latency, output_format, model_id, language_code, voice_settings, pronunciation_dictionary_locators, seed, previous_text, next_text, previous_request_ids, next_request_ids, use_pvc_as_ivc, apply_text_normalization, apply_language_text_normalization, request_options)\u001b[39m\n\u001b[32m    199\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ApiError(\n\u001b[32m    200\u001b[39m             status_code=_response.status_code, headers=\u001b[38;5;28mdict\u001b[39m(_response.headers), body=_response.text\n\u001b[32m    201\u001b[39m         )\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code=_response.status_code, headers=\u001b[38;5;28mdict\u001b[39m(_response.headers), body=_response_json)\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Sudip Das\\SudipWorkspace\\Projects\\LangInterview\\myenv\\Lib\\site-packages\\elevenlabs\\text_to_speech\\raw_client.py:202\u001b[39m, in \u001b[36mRawTextToSpeechClient.convert.<locals>._stream\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ApiError(\n\u001b[32m    200\u001b[39m         status_code=_response.status_code, headers=\u001b[38;5;28mdict\u001b[39m(_response.headers), body=_response.text\n\u001b[32m    201\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code=_response.status_code, headers=\u001b[38;5;28mdict\u001b[39m(_response.headers), body=_response_json)\n",
      "\u001b[31mApiError\u001b[39m: headers: {'date': 'Thu, 29 Jan 2026 11:30:59 GMT', 'server': 'uvicorn', 'content-length': '476', 'content-type': 'application/json', 'access-control-allow-origin': '*', 'access-control-allow-headers': '*', 'access-control-allow-methods': 'POST, PATCH, OPTIONS, DELETE, GET, PUT', 'access-control-max-age': '600', 'strict-transport-security': 'max-age=1800;', 'x-trace-id': '0ef2054edfd70d97207f6d65958bb2af', 'x-region': 'asia-southeast1', 'via': '1.1 google', 'alt-svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'}, status_code: 401, body: {'detail': {'status': 'detected_unusual_activity', 'message': 'Unusual activity detected. Free Tier usage disabled. If you are using a proxy/VPN you might need to purchase a Paid Plan to not trigger our abuse detectors. Free Tier only works if users do not abuse it, for example by creating multiple free accounts. If we notice that many people try to abuse it, we will need to reconsider Free Tier altogether. \\nPlease play fair and purchase any Paid Subscription to continue.'}}"
     ]
    }
   ],
   "source": [
    "from elevenlabs import ElevenLabs\n",
    "from IPython.display import Audio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Initialize the ElevenLabs client\n",
    "client = ElevenLabs(\n",
    "  api_key=os.getenv(\"ELEVENLABS_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Text to convert\n",
    "text = \"This is ElevenLabs text to speech running on Google Colab.\"\n",
    "\n",
    "# Generate speech (returns a generator)\n",
    "audio_stream = client.text_to_speech.convert(\n",
    "    text=text,\n",
    "    voice_id=\"JBFqnCBsd6RMkjVDRZzb\",\n",
    "    model_id=\"eleven_multilingual_v2\",\n",
    "    output_format=\"mp3_44100_128\",\n",
    ")\n",
    "# Save to a file by iterating through the generator\n",
    "with open(\"out.mp3\", \"wb\") as f:\n",
    "    for chunk in audio_stream:\n",
    "        f.write(chunk)\n",
    "\n",
    "# Play in notebook\n",
    "Audio(\"out.mp3\", autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db88c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install: pip install gtts playsound\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "def speak_text(text: str):\n",
    "    \"\"\"Convert text to speech using Google TTS\"\"\"\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:\n",
    "        temp_path = fp.name\n",
    "    tts.save(temp_path)\n",
    "    \n",
    "    # Play using system default player on Windows\n",
    "    os.system(f'start {temp_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa727933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it\n",
    "speak_text(\"I am the AI tutor of Sudip Das.I will help you learn AI and ML concepts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89156715",
   "metadata": {},
   "source": [
    "**Chat Loop with Speaking Feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1930ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop(initial_state: AgentState):\n",
    "    curr_state = initial_state.copy()\n",
    "    print(\"\"\"Starting chat loop... \n",
    "          Type 'exit' or 'quit' to end.\"\"\")\n",
    "    \n",
    "    first_out = app.invoke(curr_state)\n",
    "    # Don't use update - directly replace the state with the output\n",
    "    curr_state = first_out\n",
    "    ai_message = first_out['messages'][-1]\n",
    "    if isinstance(ai_message, AIMessage):\n",
    "        print(f'Recruiter:\\n')\n",
    "        ai_message.pretty_print()\n",
    "        speak_text(ai_message.content)\n",
    "        if 'that\\'s it for today' in ai_message.content.lower():\n",
    "            print(\"Conversation ended by Recruiter.\")\n",
    "            return curr_state\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print(\"Exiting chat.\")\n",
    "            break\n",
    "        \n",
    "        # Create a new input state with the human message added\n",
    "        input_state = {\n",
    "            **curr_state,\n",
    "            'messages': curr_state['messages'] + [HumanMessage(content=user_input)]\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            result = app.invoke(input_state)\n",
    "            # Replace state entirely instead of updating\n",
    "            curr_state = result\n",
    "        except Exception as e:\n",
    "            print(f\"Error during invocation: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "            \n",
    "        ai_message = result['messages'][-1]\n",
    "        if isinstance(ai_message, AIMessage):\n",
    "            print(f'Recruiter:\\n')\n",
    "            ai_message.pretty_print()\n",
    "            speak_text(ai_message.content)\n",
    "            if 'that\\'s it for today' in ai_message.content.lower():\n",
    "                print(\"Conversation ended by Recruiter.\")\n",
    "                break\n",
    "        elif isinstance(ai_message, ToolMessage):\n",
    "            print(f'Recruiter used tool: {ai_message.name}')\n",
    "            ai_message.pretty_print()\n",
    "        else:\n",
    "            print(f\"AI Recruiter (Other Message Type): \\n\")\n",
    "            ai_message.pretty_print()\n",
    "        \n",
    "    return curr_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d70fd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chat loop... \n",
      "          Type 'exit' or 'quit' to end.\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! I'm your interviewer today from Data Solutions Inc. We're excited to have you here. To start, could you please introduce yourself briefly?\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for the introduction, Sudip. I see you've worked on an interesting project called \"Multimodal-RAG-Forge.\" Could you tell me more about this project? Specifically, what challenges did you face while building this system, and how did you overcome them?\n",
      "\n",
      "tool used: `candidate_resume_retriever`\n",
      "\n",
      "tool used: `interview_document_retriever`\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for the overview. Let's dive deeper into your experience with LLMs.\n",
      "\n",
      "Question one: What challenges do LLMs face in deployment?\n",
      "\n",
      "tool used: `interview_document_retriever`\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for your response. You mentioned that deployment and retraining costs are significant challenges. Could you elaborate on how you would mitigate these challenges in a real-world scenario? For example, are there specific strategies or tools you would use to optimize deployment or reduce retraining costs?\n",
      "\n",
      "tool used: `interview_document_retriever`\n",
      "Recruiter used tool: save_report_as_pdf\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_report_as_pdf\n",
      "\n",
      "Report successfully saved to: c:\\Users\\Sudip Das\\SudipWorkspace\\Projects\\LangInterview\\notebooks\\Interview_Report_Data Solutions Inc._AI Engineer.pdf\n",
      "Exiting chat.\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"mode\": \"friendly\",\n",
    "    \"num_of_q\": 1,\n",
    "    \"num_of_follow_up\": 1,\n",
    "    \"position\": \"AI Engineer\",\n",
    "    \"company_name\": \"Data Solutions Inc.\",\n",
    "    \"messages\": [HumanMessage(content=\"Hi\")],\n",
    "    \"evaluation_result\": \"\",\n",
    "    \"hr_report\": \"\"\n",
    "}\n",
    "# Start the chat loop\n",
    "final_state = chat_loop(initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932e1ce",
   "metadata": {},
   "source": [
    "### **STT Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cea3030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Microphones:\n",
      "0: Microsoft Sound Mapper - Input\n",
      "1: Microphone Array (Intel¬Æ Smart \n",
      "4: Primary Sound Capture Driver\n",
      "5: Microphone Array (Intel¬Æ Smart Sound Technology for Digital Microphones)\n",
      "9: Microphone Array (Intel¬Æ Smart Sound Technology for Digital Microphones)\n",
      "10: Stereo Mix (Realtek HD Audio Stereo input)\n",
      "11: Microphone (Realtek HD Audio Mic input)\n",
      "14: PC Speaker (Realtek HD Audio 2nd output with SST)\n",
      "17: PC Speaker (Realtek HD Audio output with SST)\n",
      "18: Microphone Array 1 ()\n",
      "19: Microphone Array 2 ()\n",
      "20: Microphone Array 3 ()\n",
      "21: Microphone Array 4 ()\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "print(\"Available Microphones:\")\n",
    "devices = sd.query_devices()\n",
    "for i, device in enumerate(devices):\n",
    "    if device['max_input_channels'] > 0:\n",
    "        print(f\"{i}: {device['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6522b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19ee5e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Whisper model...\n",
      "Model loaded and ready.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing Whisper model...\")\n",
    "model_root = \"./whisper_models\"\n",
    "os.makedirs(model_root, exist_ok=True)\n",
    "\n",
    "global_model = whisper.load_model(\"base\", download_root=model_root)\n",
    "print(\"Model loaded and ready.\")\n",
    "\n",
    "def record_and_transcribe(duration=5, fs=16000, device=None, model=global_model):\n",
    "    \"\"\"\n",
    "    Records audio and transcribes.\n",
    "    Uses the pre-loaded 'model' to avoid disk-reading delays.\n",
    "    \"\"\"\n",
    "    print(\"Recording...\")\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, device=device)\n",
    "    sd.wait()  \n",
    "    print(\"Recording complete.\")\n",
    "    \n",
    "    # Save to a temporary WAV file\n",
    "    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as fp:\n",
    "        temp_wav_path = fp.name\n",
    "        sf.write(temp_wav_path, recording, fs)\n",
    "    \n",
    "    print(\"Transcribing audio...\")\n",
    "    result = model.transcribe(temp_wav_path)\n",
    "    transcription = result['text']\n",
    "    \n",
    "    # Clean up\n",
    "    os.remove(temp_wav_path)\n",
    "    \n",
    "    print(f\"Transcription: {transcription}\")\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "69f06ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording complete.\n",
      "Transcribing audio...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sudip Das\\SudipWorkspace\\Projects\\LangInterview\\myenv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  I am Sudeed Das and cut inly and starting in IIT IISM then.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I am Sudeed Das and cut inly and starting in IIT IISM then.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_and_transcribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b53c4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio # Capture microphone audio\n",
    "import websocket # Real-time streaming to AssemblyAI\n",
    "import json\n",
    "import threading # Run audio streaming & websocket in parallel\n",
    "import time\n",
    "import wave\n",
    "from urllib.parse import urlencode # Build WebSocket query params\n",
    "from datetime import datetime\n",
    "import os\n",
    "import assemblyai as aai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f49fd48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSEMBLYAI_API_KEY = os.getenv(\"ASSEMBLYAI_API_KEY\")\n",
    "CONNECTION_PARAMS = {\n",
    "    \"sample_rate\": 16000,\n",
    "    \"format_turns\": True,\n",
    "}\n",
    "# Audio configuration\n",
    "API_ENDPOINT_BASE_URL = \"wss://streaming.assemblyai.com/v3/ws\"\n",
    "API_ENDPOINT = f\"{API_ENDPOINT_BASE_URL}?{urlencode(CONNECTION_PARAMS)}\"\n",
    "FRAMES_PER_BUFFER = 800\n",
    "SAMPLE_RATE = 16000\n",
    "CHANNELS = 1\n",
    "FORMAT = pyaudio.paInt16\n",
    "\n",
    "# Global variable to control streaming\n",
    "audio = None\n",
    "stream = None\n",
    "ws_app = None\n",
    "audio_thread = None\n",
    "stop_event = threading.Event()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4295749c",
   "metadata": {},
   "source": [
    "### Web Soceket event handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c02f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_open(ws):\n",
    "    print(\"WebSocket connection opened.\")\n",
    "\n",
    "    def stream_audio(*args):\n",
    "        global stream\n",
    "        try:\n",
    "            # 1. Initialize the stream\n",
    "            stream = audio.open(\n",
    "                format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=SAMPLE_RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=FRAMES_PER_BUFFER\n",
    "            )           \n",
    "            print(\"Streaming started...\")\n",
    "            \n",
    "            while not stop_event.is_set():\n",
    "                data = stream.read(FRAMES_PER_BUFFER, exception_on_overflow=False)\n",
    "                \n",
    "                # 3. Send and catch potential socket errors\n",
    "                try:\n",
    "                    ws.send(data, websocket.ABNF.OPCODE_BINARY)\n",
    "                except websocket.WebSocketConnectionClosedException:\n",
    "                    print(\"Socket closed by server.\")\n",
    "                    break\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error during streaming: {e}\")\n",
    "            \n",
    "        finally:\n",
    "            # 4. Reliable cleanup\n",
    "            if stream:\n",
    "                stream.stop_stream()\n",
    "                stream.close()\n",
    "            print(\"Audio streaming stopped.\")\n",
    "\n",
    "    # Start the thread\n",
    "    audio_thread = threading.Thread(target=stream_audio, daemon=True)\n",
    "    audio_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afd398e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_message(ws, message):\n",
    "    try:\n",
    "        data = json.loads(message)\n",
    "        msg_type = data.get(\"type\")\n",
    "        \n",
    "        if msg_type == \"Begin\":\n",
    "            print(\"Transcription session has started.\")\n",
    "            session_id = data.get(\"id\")\n",
    "            expires_at = data.get(\"expires_at\")\n",
    "            print(f\"Session ID: {session_id}, Expires at: {datetime.fromtimestamp(expires_at)}\")\n",
    "        \n",
    "        elif msg_type == \"Turn\":\n",
    "            print(f\"Transcription Turn: {data.get('id')}\")\n",
    "            transcript = data.get('transcript', '')\n",
    "            formatted = data.get('turn_is_formatted', False)\n",
    "            if formatted:\n",
    "                print(f\"Transcript: {transcript} (Formatted: {formatted})\")\n",
    "            else:\n",
    "                print(f'\\r{transcript}', end='', flush=True)\n",
    "                \n",
    "        elif msg_type == \"Termination\":\n",
    "            print(\"Transcription session has ended by server.\")\n",
    "            audio_duration = data.get(\"audio_duration_seconds\", 0)\n",
    "            session_duration = data.get(\"session_duration_seconds\", 0)\n",
    "            print(f\"Audio Duration: {audio_duration} seconds. Session Duration: {session_duration} seconds.\")\n",
    "            stop_event.set()\n",
    "            \n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Received non-JSON message from server.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing message: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bee132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_error(ws, error):\n",
    "    print(f\"WebSocket error: {error}\")\n",
    "    stop_event.set()\n",
    "    \n",
    "def on_close(ws, close_status_code, close_msg):\n",
    "    print(f\"WebSocket connection closed: {close_status_code} - {close_msg}\")\n",
    "\n",
    "    # Ensure audio resources are released\n",
    "    global stream, audio\n",
    "    stop_event.set()  # Signal audio thread just in case it's still running\n",
    "    if stream:\n",
    "        if stream.is_active():\n",
    "            stream.stop_stream()\n",
    "        stream.close()\n",
    "        stream = None\n",
    "    if audio:\n",
    "        audio.terminate()\n",
    "        audio = None\n",
    "    # Try to join the audio thread to ensure clean exit\n",
    "    if audio_thread and audio_thread.is_alive():\n",
    "        audio_thread.join(timeout=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6455298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    global audio, stream, ws_app\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stop_event.clear()\n",
    "    try:\n",
    "        stream = audio.open(\n",
    "            format=FORMAT,\n",
    "            channels=CHANNELS,\n",
    "            rate=SAMPLE_RATE,\n",
    "            input=True,\n",
    "            frames_per_buffer=FRAMES_PER_BUFFER\n",
    "        )\n",
    "        print('microphone is set up.')\n",
    "        print('Speak now into your microphone... Press Ctrl+C to stop.')\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing microphone: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Create WebSocket app\n",
    "    ws_app = websocket.WebSocketApp(\n",
    "        API_ENDPOINT,\n",
    "        header={\"Authorization\": ASSEMBLYAI_API_KEY},\n",
    "        on_open=on_open,\n",
    "        on_message=on_message,\n",
    "        on_error=on_error,\n",
    "        on_close=on_close\n",
    "    )\n",
    "    ws_thread = threading.Thread(target=ws_app.run_forever, daemon=True)\n",
    "    ws_thread.start()\n",
    "    \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        max_duration = 30\n",
    "        while not stop_event.is_set():\n",
    "            if time.time() - start_time > max_duration:\n",
    "                print(\"Max duration reached. Stopping...\")\n",
    "                stop_event.set()\n",
    "                break\n",
    "            time.sleep(0.1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Keyboard interrupt received. Stopping...\")\n",
    "        stop_event.set()\n",
    "        if ws_app and ws_app.sock and ws_app.sock.connected:\n",
    "            try:\n",
    "                terminate_msg = json.dumps({\"type\": \"Terminate\"})\n",
    "                print(\"Sending termination message to server...\")\n",
    "                ws_app.send(terminate_msg)\n",
    "                time.sleep(5)  \n",
    "            except Exception as e:\n",
    "                print(f\"Error sending termination message: {e}\")\n",
    "                \n",
    "        if ws_app:\n",
    "            ws_app.close()\n",
    "        ws_thread.join(timeout=2.0)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "    finally:\n",
    "        # Final cleanup\n",
    "        if stream:\n",
    "            if stream.is_active():\n",
    "                stream.stop_stream()\n",
    "            stream.close()\n",
    "        if audio:\n",
    "            audio.terminate()\n",
    "        print(\"Program terminated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8e6912b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microphone is set up.\n",
      "Speak now into your microphone... Press Ctrl+C to stop.\n",
      "WebSocket connection opened.\n",
      "Transcription session has started.\n",
      "Session ID: 1ef493a3-bd69-4fa8-92b9-e9e702c9f4a7, Expires at: 2026-01-29 16:21:22\n",
      "Streaming started...\n",
      "Transcription Turn: None\n",
      "Transcription Turn: None\n",
      "hiTranscription Turn: None\n",
      "hi iTranscription Turn: None\n",
      "hi i amTranscription Turn: None\n",
      "hi i amTranscription Turn: None\n",
      "hi i amTranscription Turn: None\n",
      "hi i amTranscription Turn: None\n",
      "hi i am sudeepTranscription Turn: None\n",
      "hi i am sudeepTranscription Turn: None\n",
      "hi i am sudeep dasTranscription Turn: None\n",
      "hi i am sudeep das currentlyTranscription Turn: None\n",
      "hi i am sudeep das currently iTranscription Turn: None\n",
      "hi i am sudeep das currently i amTranscription Turn: None\n",
      "hi i am sudeep das currently i am livingTranscription Turn: None\n",
      "hi i am sudeep das currently i am living inTranscription Turn: None\n",
      "hi i am sudeep das currently i am living inTranscription Turn: None\n",
      "hi i am sudeep das currently i am living inTranscription Turn: None\n",
      "hi i am sudeep das currently i am living in dhanbadTranscription Turn: None\n",
      "Transcript: Hi, I am sudeep das. Currently I am living in dhanbad. (Formatted: True)\n",
      "Transcription Turn: None\n",
      "Transcription Turn: None\n",
      "iTranscription Turn: None\n",
      "i amTranscription Turn: None\n",
      "i am actuallyTranscription Turn: None\n",
      "i am actually fromTranscription Turn: None\n",
      "i am actually fromTranscription Turn: None\n",
      "i am actually from eastTranscription Turn: None\n",
      "i am actually from eastTranscription Turn: None\n",
      "i am actually from east bengalTranscription Turn: None\n",
      "Transcript: I am actually from East Bengal. (Formatted: True)\n",
      "Transcription Turn: None\n",
      "Transcription Turn: None\n",
      "that'sTranscription Turn: None\n",
      "that's itTranscription Turn: None\n",
      "that's it aboutTranscription Turn: None\n",
      "that's it aboutTranscription Turn: None\n",
      "that's it about meTranscription Turn: None\n",
      "Transcript: That's it about me. (Formatted: True)\n",
      "Transcription Turn: None\n",
      "Transcription Turn: None\n",
      "whatTranscription Turn: None\n",
      "what youTranscription Turn: None\n",
      "what youTranscription Turn: None\n",
      "what you doTranscription Turn: None\n",
      "Transcript: What you do. (Formatted: True)\n",
      "Transcription Turn: None\n",
      "Transcription Turn: None\n",
      "thankTranscription Turn: None\n",
      "thank youTranscription Turn: None\n",
      "Transcript: Thank you. (Formatted: True)\n",
      "Max duration reached. Stopping...\n",
      "Program terminated.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "505f3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_realtime_stt(api_key: str):\n",
    "    \"\"\"\n",
    "    Starts real-time STT using AssemblyAI WebSocket API and mic input.\n",
    "\n",
    "    Press Ctrl+C to stop.\n",
    "    \"\"\"\n",
    "    # --- Config ---\n",
    "    CONNECTION_PARAMS = {\n",
    "        \"sample_rate\": 16000,\n",
    "        \"format_turns\": True,\n",
    "    }\n",
    "    API_ENDPOINT = f\"wss://streaming.assemblyai.com/v3/ws?{urlencode(CONNECTION_PARAMS)}\"\n",
    "    FRAMES_PER_BUFFER = 800\n",
    "    SAMPLE_RATE = 16000\n",
    "    CHANNELS = 1\n",
    "    FORMAT = pyaudio.paInt16\n",
    "\n",
    "    # --- Globals ---\n",
    "    stop_event = threading.Event()\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = None\n",
    "    ws_app = None\n",
    "\n",
    "    # --- Callbacks ---\n",
    "    def on_open(ws):\n",
    "        def send_audio():\n",
    "            while not stop_event.is_set():\n",
    "                try:\n",
    "                    audio_data = stream.read(FRAMES_PER_BUFFER, exception_on_overflow=False)\n",
    "                    ws.send(audio_data, websocket.ABNF.OPCODE_BINARY)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error streaming: {e}\")\n",
    "                    break\n",
    "        threading.Thread(target=send_audio, daemon=True).start()\n",
    "        print(\"Microphone streaming started...\")\n",
    "\n",
    "    def on_message(ws, message):\n",
    "        data = json.loads(message)\n",
    "        if data.get(\"type\") == \"Turn\":\n",
    "            transcript = data.get(\"transcript\", \"\")\n",
    "            if data.get(\"turn_is_final\", False):\n",
    "                print(f\"\\nFinal Transcript: {transcript}\")\n",
    "            else:\n",
    "                print(f\"\\rPartial: {transcript}\", end=\"\")\n",
    "\n",
    "    def on_error(ws, error):\n",
    "        print(f\"WebSocket error: {error}\")\n",
    "        stop_event.set()\n",
    "\n",
    "    def on_close(ws, code, msg):\n",
    "        print(f\"\\nWebSocket closed: {code} - {msg}\")\n",
    "        stop_event.set()\n",
    "        if stream:\n",
    "            if stream.is_active():\n",
    "                stream.stop_stream()\n",
    "            stream.close()\n",
    "        audio.terminate()\n",
    "\n",
    "    # --- Setup ---\n",
    "    try:\n",
    "        stream = audio.open(\n",
    "            input=True,\n",
    "            frames_per_buffer=FRAMES_PER_BUFFER,\n",
    "            channels=CHANNELS,\n",
    "            format=FORMAT,\n",
    "            rate=SAMPLE_RATE,\n",
    "        )\n",
    "        print(\"üéß Microphone ready.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Mic error: {e}\")\n",
    "        audio.terminate()\n",
    "        return\n",
    "\n",
    "    ws_app = websocket.WebSocketApp(\n",
    "        API_ENDPOINT,\n",
    "        header={\"Authorization\": api_key},\n",
    "        on_open=on_open,\n",
    "        on_message=on_message,\n",
    "        on_error=on_error,\n",
    "        on_close=on_close,\n",
    "    )\n",
    "\n",
    "    ws_thread = threading.Thread(target=ws_app.run_forever, daemon=True)\n",
    "    ws_thread.start()\n",
    "\n",
    "    try:\n",
    "        while ws_thread.is_alive():\n",
    "            time.sleep(0.1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopping...\")\n",
    "        stop_event.set()\n",
    "        if ws_app and ws_app.sock and ws_app.sock.connected:\n",
    "            ws_app.send(json.dumps({\"type\": \"Terminate\"}))\n",
    "        ws_app.close()\n",
    "        ws_thread.join()\n",
    "        print(\"Shutdown complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72ed836f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéß Microphone ready.\n",
      "Microphone streaming started...\n",
      "Partial: Currently I am looking for a job in AI Engineering.\n",
      "Stopping...\n",
      "\n",
      "WebSocket closed: None - None\n",
      "Shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "start_realtime_stt(api_key=os.getenv(\"ASSEMBLYAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c487c37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Microphones and Speakers:\n",
      "0: Microsoft Sound Mapper - Input\n",
      "1: Microphone Array (Intel√Ç¬Æ Smart \n",
      "2: Microsoft Sound Mapper - Output\n",
      "3: Speaker (Realtek(R) Audio)\n",
      "4: Primary Sound Capture Driver\n",
      "5: Microphone Array (Intel√Ç¬Æ Smart Sound Technology for Digital Microphones)\n",
      "6: Primary Sound Driver\n",
      "7: Speaker (Realtek(R) Audio)\n",
      "8: Speaker (Realtek(R) Audio)\n",
      "9: Microphone Array (Intel√Ç¬Æ Smart Sound Technology for Digital Microphones)\n",
      "10: Stereo Mix (Realtek HD Audio Stereo input)\n",
      "11: Microphone (Realtek HD Audio Mic input)\n",
      "12: Headphones 1 (Realtek HD Audio 2nd output with SST)\n",
      "13: Headphones 2 (Realtek HD Audio 2nd output with SST)\n",
      "14: PC Speaker (Realtek HD Audio 2nd output with SST)\n",
      "15: Speakers 1 (Realtek HD Audio output with SST)\n",
      "16: Speakers 2 (Realtek HD Audio output with SST)\n",
      "17: PC Speaker (Realtek HD Audio output with SST)\n",
      "18: Microphone Array 1 ()\n",
      "19: Microphone Array 2 ()\n",
      "20: Microphone Array 3 ()\n",
      "21: Microphone Array 4 ()\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "print(\"Available Microphones and Speakers:\")\n",
    "for index, name in enumerate(sr.Microphone.list_microphone_names()):\n",
    "    print(f\"{index}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "274aeaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing microphone. Please say something...\n",
      "Microphone is working! You said: I am Sudip Das\n"
     ]
    }
   ],
   "source": [
    "# test microphone\n",
    "def test_microphone():\n",
    "    r = sr.Recognizer()\n",
    "    try:\n",
    "        with sr.Microphone(device_index=1) as source:\n",
    "            print(\"Testing microphone. Please say something...\")\n",
    "            r.adjust_for_ambient_noise(source, duration=1)\n",
    "            audio = r.listen(source, timeout=10)\n",
    "        try:\n",
    "            text = r.recognize_google(audio)\n",
    "            print(f\"Microphone is working! You said: {text}\")\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Microphone is working, but could not understand the audio.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Microphone is working, but could not request results; {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Microphone test failed: {e}\")\n",
    "\n",
    "test_microphone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6513517",
   "metadata": {},
   "source": [
    "### **Integration AssymbleAI STT to chat_loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1be33b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import requests\n",
    "import time\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "\n",
    "ASSEMBLYAI_API_KEY = os.getenv(\"ASSEMBLYAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "00b68a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemblyai_transcribe(duration=5, sample_rate=16000):\n",
    "    print(f\"Recording for {duration} seconds...\")\n",
    "\n",
    "    # Record audio\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate,\n",
    "                   channels=1, dtype='int16')\n",
    "    sd.wait()\n",
    "    print(\"Recording done.\")\n",
    "    \n",
    "    # Save to a temporary WAV file\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp:\n",
    "        write_wav(tmp.name, sample_rate, audio)\n",
    "        audio_path = tmp.name\n",
    "    print(f\"Audio saved to {audio_path}. Uploading to AssemblyAI...\")\n",
    "    \n",
    "    # Upload audio file\n",
    "    headers = {\"authorization\": ASSEMBLYAI_API_KEY}\n",
    "    with open(audio_path, \"rb\") as f:\n",
    "        upload_resp = requests.post(\"https://api.assemblyai.com/v2/upload\", headers=headers, data=f)\n",
    "        \n",
    "    if upload_resp.status_code != 200:\n",
    "        print(f\"Upload failed: {upload_resp.text}\")\n",
    "        return\n",
    "    upload_url = upload_resp.json()['upload_url']\n",
    "    print(f\"Upload successful. URL: {upload_url}\")\n",
    "    \n",
    "    # Request transcription\n",
    "    transcript_resp = requests.post(\n",
    "        \"https://api.assemblyai.com/v2/transcript\",\n",
    "        headers=headers,\n",
    "        json={\"audio_url\": upload_url}\n",
    "    )\n",
    "    if transcript_resp.status_code != 200:\n",
    "        print(f\"Transcription request failed: {transcript_resp.text}\")\n",
    "        return\n",
    "    transcript_id = transcript_resp.json()['id']\n",
    "    print(f\"Transcription requested. ID: {transcript_id}. Polling for result ...\")\n",
    "    \n",
    "    # Poll for result\n",
    "    while True:\n",
    "        status_resp = requests.get(\n",
    "            f\"https://api.assemblyai.com/v2/transcript/{transcript_id}\", \n",
    "            headers=headers\n",
    "        )\n",
    "        status_data = status_resp.json()\n",
    "        if status_data['status'] == 'completed':\n",
    "            print(\"Transcription completed:\")\n",
    "            print(status_data['text'])\n",
    "            os.remove(audio_path)  # Clean up temp file\n",
    "            return status_data['text']\n",
    "            break\n",
    "        elif status_data['status'] == 'error':\n",
    "            print(f\"Transcription error: {status_data['error']}\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Transcription status: {status_data['status']}. Waiting...\")\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0254a3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test of AssemblyAI transcription:\n",
      "\n",
      "Recording for 5 seconds...\n",
      "Recording done.\n",
      "Audio saved to C:\\Users\\SUDIPD~1\\AppData\\Local\\Temp\\tmpg3qij51c.wav. Uploading to AssemblyAI...\n",
      "Upload successful. URL: https://cdn.assemblyai.com/upload/7a0e6efa105555a5bb3231814cd1a2080ed4ef874a8c02a715def2dd1492c873/d40f47d8-1ee5-4634-9fe2-c4e74be8b641\n",
      "Transcription requested. ID: a246488f-db5b-4526-acb5-8bed69d0b2cc. Polling for result ...\n",
      "Transcription completed:\n",
      "Hi, my name is Sudibdash. What else is going on?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi, my name is Sudibdash. What else is going on?'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Final test of AssemblyAI transcription:\\n\")\n",
    "assemblyai_transcribe(duration=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "768a9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop(initial_state: AgentState):\n",
    "    current_state = initial_state.copy()\n",
    "    try:\n",
    "        while True:\n",
    "            print(\"Waiting for your input (type 'exit' to quit)...\")\n",
    "            user_input = assemblyai_transcribe(duration=10)\n",
    "            if not user_input:\n",
    "                continue\n",
    "            if user_input.lower() in ['exit', 'quit']:\n",
    "                print(\"Exiting chat.\")\n",
    "                break\n",
    "            current_state['messages'].append(HumanMessage(content=user_input))\n",
    "            result = app.invoke(current_state)\n",
    "            current_state = result\n",
    "            ai_message = result['messages'][-1]\n",
    "            \n",
    "            print(f'Recruiter:\\n')\n",
    "            ai_message.pretty_print()\n",
    "            if isinstance(ai_message, AIMessage):\n",
    "                speak_text(ai_message.content)\n",
    "            elif isinstance(ai_message, ToolMessage):\n",
    "                print(f'Recruiter used tool: {ai_message.name}')\n",
    "                ai_message.pretty_print()\n",
    "            if 'that\\'s it for today' in ai_message.content.lower():\n",
    "                print(\"Conversation ended by Recruiter.\")\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"Error during chat loop: {e}\")\n",
    "    return current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "73b0cccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for your input (type 'exit' to quit)...\n",
      "Recording for 10 seconds...\n",
      "Recording done.\n",
      "Audio saved to C:\\Users\\SUDIPD~1\\AppData\\Local\\Temp\\tmpc4h8mcjl.wav. Uploading to AssemblyAI...\n",
      "Upload successful. URL: https://cdn.assemblyai.com/upload/a9b023b614b75daea4f8fe92cc8219ca9cd4cc75bca65166fd7f80dcb08c16d4/ce89abf3-f42a-4c57-894c-be8a83681dc5\n",
      "Transcription requested. ID: 415152cf-d230-4d20-aafc-7ce8b098d66e. Polling for result ...\n",
      "Transcription status: processing. Waiting...\n",
      "Transcription completed:\n",
      "Hi, I am sudip dash.\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Sudip, thank you for taking the time to interview with us today. It's great to meet you.  \n",
      "Question 1, could you please introduce yourself and tell us a bit about your background?  \n",
      "Question 2, I noticed on your resume that you built an AI EDA agent for automated CSV analysis at Unihox. Could you walk us through that project, the tools you used, and what impact it had?  \n",
      "Question 3, from our knowledge base, here's a core AI/ML question: Explain how you would handle imbalanced datasets in a classification problem, and what evaluation metrics would you use to assess the model's performance.\n",
      "Waiting for your input (type 'exit' to quit)...\n",
      "Recording for 10 seconds...\n",
      "Recording done.\n",
      "Audio saved to C:\\Users\\SUDIPD~1\\AppData\\Local\\Temp\\tmp7n5bvl3o.wav. Uploading to AssemblyAI...\n",
      "Upload successful. URL: https://cdn.assemblyai.com/upload/6a3f765af4ac977b6e02c46a5a17a3d730a252763c249c6f03492ede4c90a670/01a4ce61-4bd4-4712-88a4-8049f7bb8a65\n",
      "Transcription requested. ID: 6fe4ca66-b263-49cd-ba24-86b115c3b94f. Polling for result ...\n",
      "Transcription completed:\n",
      "Okay? Of course. Thank you for introducing, giving me this opportunity. I am Sudip Das from Howdah.\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for sharing, Sudip. To continue, could you tell us a bit more about your academic background and any relevant coursework or projects that have prepared you for AI/ML engineering? That would be a follow‚Äëup to Question‚ÄØ1.\n",
      "\n",
      "Now, I‚Äôd like to dive into the project you mentioned on your resume. Could you walk us through the AI EDA agent you built at Unihox, the tools you used, and the impact it had on users or the business? That‚Äôs Question‚ÄØ2.\n",
      "\n",
      "Finally, I have a core AI/ML question from our knowledge base: Explain how you would handle imbalanced datasets in a classification problem, and what evaluation metrics you would use to assess the model‚Äôs performance. That‚Äôs Question‚ÄØ3.\n",
      "Waiting for your input (type 'exit' to quit)...\n",
      "Recording for 10 seconds...\n",
      "Recording done.\n",
      "Audio saved to C:\\Users\\SUDIPD~1\\AppData\\Local\\Temp\\tmppu1k78e2.wav. Uploading to AssemblyAI...\n",
      "Upload successful. URL: https://cdn.assemblyai.com/upload/7caf9e50609183472a95ff79285ddb6054dc8fc37678098db528323d63005816/bb127eb0-cd7e-4d9e-8d70-8c3d0c3f6106\n",
      "Transcription requested. ID: a8b4e420-c394-49bf-92e1-d8284f6c8801. Polling for result ...\n",
      "Transcription completed:\n",
      "Of course I will try to deep down my project. Actually, I basically made lots of project.\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure, I‚Äôd be happy to hear more about your projects. To get a clearer picture of your experience, could you tell us about the **AI EDA agent** you built at Unihox, especially the **technical stack you used** (e.g., frameworks like LangChain or CrewAI) and any **specific challenges you faced** during development? That would help us understand your practical problem-solving approach.  \n",
      "\n",
      "(Alternatively, if you‚Äôd prefer to highlight another project from your resume‚Äîlike your coursework in ML or tools like Pytorch‚Äîfeel free to mention it, and I‚Äôll tailor my follow‚Äëup accordingly!)  \n",
      "\n",
      "For Question‚ÄØ3, whenever you‚Äôre ready, please share your thoughts on handling imbalanced datasets. I‚Äôm here to listen.  \n",
      "\n",
      "Let‚Äôs keep going!  \n",
      "\n",
      "(And don‚Äôt worry‚Äîthis is a safe space for brainstorming. If you‚Äôre unsure about anything, just ask.)\n",
      "Waiting for your input (type 'exit' to quit)...\n",
      "Recording for 10 seconds...\n",
      "Recording done.\n",
      "Audio saved to C:\\Users\\SUDIPD~1\\AppData\\Local\\Temp\\tmpc1oowu0v.wav. Uploading to AssemblyAI...\n",
      "Upload successful. URL: https://cdn.assemblyai.com/upload/9fa993d7b335140919c49b3789d0e45f6b51b8e646425f0d0470a7698129546b/28ed4756-f41e-411d-b2b7-baa5bfaa1728\n",
      "Transcription requested. ID: 1ce7384a-321f-4e0c-b24c-722587366213. Polling for result ...\n",
      "Transcription completed:\n",
      "Thank you for giving this opportunity. I have not remember any project.\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Sudip, thank you for the introduction. I understand you might not remember every detail of the AI‚ÄØEDA agent you built at Unihox. Could you share any information you do recall about that project‚Äîperhaps the main goal, the key tools you used such as LangChain or LangGraph, the libraries you leveraged, or any challenges you faced during development? Once you feel comfortable, we‚Äôll move on to the next question about handling imbalanced datasets.\n",
      "Waiting for your input (type 'exit' to quit)...\n",
      "Recording for 10 seconds...\n",
      "Recording done.\n",
      "Audio saved to C:\\Users\\SUDIPD~1\\AppData\\Local\\Temp\\tmpggc96p_m.wav. Uploading to AssemblyAI...\n",
      "Upload successful. URL: https://cdn.assemblyai.com/upload/8dd058bbe949aa21412f22e149ac5f7c5307f0810228d02279ed4027f8f441b8/26032073-8890-4c9f-b424-961f02cae5d4\n",
      "Transcription requested. ID: 0beb9057-af02-44a2-9aea-c9f12f4a4e13. Polling for result ...\n",
      "Transcription completed:\n",
      "Of course, the ed agent. There is a agent GPT in germany, which analyz.\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great to meet you, Sudip. I‚Äôve enjoyed hearing about your background. Let‚Äôs dive a little deeper into your Unihox experience and then cover a key technical concept.\n",
      "\n",
      "**Question‚ÄØ2 ‚Äì Project follow‚Äëup:** Could you tell us more about the AI‚ÄØEDA agent you built? Specifically, I‚Äôm interested in the technical choices you made. Which frameworks or libraries did you use to design the agent‚Äîperhaps LangChain or LangGraph‚Äîand how did you integrate them with data‚Äëvisualization libraries to generate the 15+ exportable plots? What were the main challenges you ran into during development, and how did you overcome them?\n",
      "\n",
      "**Question‚ÄØ3 ‚Äì Core AI/ML concept:** Now, shifting gears a bit, could you explain how you would handle imbalanced datasets in a classification problem and which evaluation metrics you would prioritize to assess the model‚Äôs performance? I‚Äôd love to hear your approach, any techniques you‚Äôve used before, and why you‚Äôd choose those metrics.\n",
      "Waiting for your input (type 'exit' to quit)...\n",
      "Recording for 10 seconds...\n",
      "Recording done.\n",
      "Audio saved to C:\\Users\\SUDIPD~1\\AppData\\Local\\Temp\\tmp6u4ftqg8.wav. Uploading to AssemblyAI...\n",
      "Upload successful. URL: https://cdn.assemblyai.com/upload/2e24d09a2d31017e1641a9afe4999fa3224b5c61c448bbacfcaff3462edb4091/da7261ad-e2f4-4666-81af-2837dc82bbbe\n",
      "Transcription requested. ID: 0300f0a8-41f2-4aef-b715-ebf5440576d5. Polling for result ...\n",
      "Transcription completed:\n",
      "I have handled the misclassification with smooth SBM smooth and also.\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for sharing that, Sudip. Your mention of handling misclassification with ‚Äúsmooth‚ÄØSBM‚ÄØsmooth‚Äù sounds intriguing. Could you elaborate a bit on that? Specifically, I‚Äôd like to understand:\n",
      "\n",
      "- What approach or technique you used (for example, did you employ a smooth stochastic block model, a smoothing method, or something else?)  \n",
      "- Which libraries or tools you leveraged to implement it, and how you integrated that with the rest of your workflow.  \n",
      "- How this approach impacted your model‚Äôs accuracy, especially in terms of reducing misclassification rates.  \n",
      "- Which evaluation metrics you examined to verify the improvement‚Äîsuch as precision, recall, F1‚Äëscore, ROC‚ÄëAUC, or others‚Äîand why you chose those metrics.\n",
      "\n",
      "Your insights will help us gauge your problem‚Äësolving style and technical depth.\n",
      "Waiting for your input (type 'exit' to quit)...\n",
      "Recording for 10 seconds...\n",
      "Recording done.\n",
      "Audio saved to C:\\Users\\SUDIPD~1\\AppData\\Local\\Temp\\tmpi4vqsejs.wav. Uploading to AssemblyAI...\n",
      "Upload successful. URL: https://cdn.assemblyai.com/upload/b166f72a03cece3f0bf41d619ce1250b11daf9e43d1819ba583964b352759a43/afbd60a5-5028-456e-833b-64b943ab9ac3\n",
      "Transcription requested. ID: e8a67e25-f253-4716-a146-4d4c558d21bf. Polling for result ...\n",
      "Transcription completed:\n",
      "Thank you. I have no idea about that. Sorry.\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Sudip, thank you for letting me know. No worries at all‚Äîeveryone has areas where they‚Äôre still learning.  \n",
      "\n",
      "Let‚Äôs shift to a concept we definitely want to see how you‚Äôd approach:  \n",
      "\n",
      "**Question‚ÄØ3:** Could you walk us through how you would handle imbalanced datasets in a classification problem, and which evaluation metrics you would prioritize to assess the model‚Äôs performance? For example, would you consider techniques like oversampling the minority class, undersampling the majority class, using class‚Äëweighting, generating synthetic samples (SMOTE), or perhaps employing an ensemble method? And which metrics‚Äîprecision, recall, F1‚Äëscore, ROC‚ÄëAUC, PR‚ÄëAUC, or others‚Äîwould you look at first to understand how well the model is doing on the minority class?  \n",
      "\n",
      "Feel free to share any specific methods you‚Äôve tried in the past or any tools you‚Äôd reach for. This will help us gauge your practical problem‚Äësolving style.  \n",
      "\n",
      "Let‚Äôs hear your thoughts on that.\n",
      "Waiting for your input (type 'exit' to quit)...\n",
      "Recording for 10 seconds...\n",
      "Recording done.\n",
      "Audio saved to C:\\Users\\SUDIPD~1\\AppData\\Local\\Temp\\tmp73kxflsx.wav. Uploading to AssemblyAI...\n",
      "Upload successful. URL: https://cdn.assemblyai.com/upload/53baaa4d4c681e82f211096c717ba45063a9b8fa01ffc578a2f99f5664b3294a/9f8991b7-5a4f-4c21-b1dd-8fdd869c1428\n",
      "Transcription requested. ID: 6f62b57d-da4d-4a23-95c6-52f88cdc22d5. Polling for result ...\n",
      "Transcription completed:\n",
      "Hello? Okay, I can deep dive to you in my projects like this.\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Sudip, thanks for clarifying. Let‚Äôs dive a little deeper into the AI‚ÄØEDA agent you mentioned.  \n",
      "\n",
      "**Question‚ÄØ2 follow‚Äëup:** Could you tell us more about the project you built at Unihox? Specifically, which frameworks or libraries did you use to design the agent‚Äîperhaps LangChain or LangGraph‚Äîand how you integrated them with data‚Äëvisualization tools like Seaborn or Plotly to generate the 15+ exportable plots? I‚Äôd also like to hear about any challenges you faced during development and how you overcame them, as well as any metrics you tracked to gauge the agent‚Äôs impact.\n",
      "\n",
      "**Question‚ÄØ3:** Shifting gears a bit, how would you handle imbalanced datasets in a classification problem, and which evaluation metrics would you prioritize to assess the model‚Äôs performance? For example, would you consider oversampling, class weighting, synthetic data generation, or ensemble methods, and why would you choose metrics such as precision, recall, F1‚Äëscore, ROC‚ÄëAUC, or others?\n",
      "\n",
      "Feel free to share any relevant experience or ideas you have on these topics. I‚Äôm looking forward to hearing your approach.\n",
      "Waiting for your input (type 'exit' to quit)...\n",
      "Recording for 10 seconds...\n",
      "Recording done.\n",
      "Audio saved to C:\\Users\\SUDIPD~1\\AppData\\Local\\Temp\\tmpqgv9jnam.wav. Uploading to AssemblyAI...\n",
      "Upload successful. URL: https://cdn.assemblyai.com/upload/7e1f12ffccbe314788fe8d4abb6b0d640102b09ffcafdb98f1d82b4385ac576c/87452a3f-986e-4d6d-a68b-958d7a7de01f\n",
      "Transcription requested. ID: 27bae93f-1bfa-4a73-ae28-d8cc6961efff. Polling for result ...\n",
      "Transcription status: processing. Waiting...\n",
      "Transcription completed:\n",
      "Okay, I have no idea about that, but.\n",
      "Recruiter:\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Sudip, thank you for joining us today. I‚Äôm happy to hear about your background.\n",
      "\n",
      "**Question‚ÄØ1:** Could you briefly introduce yourself, tell us about your academic experience at the Indian Institute of Technology (ISM) Dhanbad and the University of Calcutta, and share why you‚Äôre interested in pursuing an AI/ML engineering role?\n",
      "\n",
      "**Question‚ÄØ2:** The AI‚ÄØEDA agent you built at Unihox sounds like an interesting project. If you‚Äôd like, you could walk us through the main goal of that agent, the frameworks or libraries you used (for example LangChain, LangGraph, PyTorch, Seaborn, etc.), how you integrated the data‚Äëanalysis workflow with visualization, and any specific challenges you encountered. If that project is still fresh in your memory, that would be great‚Äîotherwise, feel free to describe any other recent project from your resume (perhaps a Kaggle competition or a coursework assignment) that involves automated data analysis or classification.\n",
      "\n",
      "**Question‚ÄØ3:** Let‚Äôs shift to a core technical topic. How would you handle imbalanced datasets in a classification problem? What techniques or tools would you consider‚Äîsuch as oversampling, undersampling, class weighting, SMOTE, ensemble methods, or custom loss functions? And which evaluation metrics would you prioritize to assess performance, and why (e.g., precision, recall, F1‚Äëscore, ROC‚ÄëAUC, PR‚ÄëAUC, or other)?\n",
      "\n",
      "Whenever you‚Äôre ready, we can discuss each question step by step. Looking forward to hearing your perspective.\n",
      "Error during chat loop: Failed to connect. Probable cause: Unknown\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"mode\": \"friendly\",\n",
    "    \"num_of_q\": 1,\n",
    "    \"num_of_follow_up\": 1,\n",
    "    \"position\": \"AI/ML Engineer\",\n",
    "    \"company_name\": \"Global Tech Solutions\",\n",
    "    \"messages\": [HumanMessage(content=\"Hi\")],\n",
    "    \"evaluation_result\": \"\",\n",
    "    \"hr_report\": \"\"\n",
    "}\n",
    "# Start the chat loop\n",
    "final_state = chat_loop(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9aab2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
